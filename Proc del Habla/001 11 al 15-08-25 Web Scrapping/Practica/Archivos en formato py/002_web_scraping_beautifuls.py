# -*- coding: utf-8 -*-
"""002_Web_Scraping_BeautifulS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sj94M5P6LzUtel1tVAqoanmrwFDGgcQ_
"""

#游 Parte 1: Descarga del HTML y parsing
import requests
from bs4 import BeautifulSoup

# Descargamos el HTML de "La Odisea" desde Project Gutenberg y lo analizamos con BeautifulSoup.

url = "https://www.gutenberg.org/cache/epub/58221/pg58221-images.html"
contenido = requests.get(url).text

soup = BeautifulSoup(contenido, "html.parser")

#游 Parte 2: Exploraci칩n inicial del contenido HTML
# Buscamos y mostramos las etiquetas <p>, <h1> e <i> del texto HTML.
# Esto nos da una primera idea de la estructura del documento.

parrafos = soup.find_all("p")
print(parrafos)

h1 = soup.find_all("h1")
print(h1)

italicas = soup.find_all("i")
print(italicas)

from collections import Counter #Counter es una clase de la biblioteca est치ndar de Python (dentro del m칩dulo collections) que cuenta la cantidad de veces que aparece cada elemento en una lista, string, etc.

parrafos = str(soup.find_all("p"))
print(parrafos)

#游 Parte 3: Conteo de menciones espec칤ficas
print(parrafos.count("Ulises"))# Conteo r치pido de veces que aparece la palabra "Ulises" en las etiquetas <p>.

#游 Parte 4: Funci칩n para buscar cualquier palabra
# Funci칩n para buscar cu치ntas veces aparece una palabra (sin distinci칩n entre may칰sculas/min칰sculas) en el HTML.
def buscar_palabra(palabra):
  ocurrencias = str(soup).lower().count(palabra.lower())
  print(f"Encontraste la palabra '{palabra}' {ocurrencias} veces")

buscar_palabra("Ciclope")
buscar_palabra("Minerva")
buscar_palabra("Alc칤noo")
buscar_palabra("CANTO")

"""## Algo divertido"""

import random

#游 Parte 5: Elegir un pasaje aleatorio de la obra
# 2. Mostrar un pasaje aleatorio de la Odisea
parrafos = soup.find_all("p")
parrafo_aleatorio = random.choice(parrafos).text.strip()

print("\nLee un pasaje aleatorio de la Odisea")
print("-------------------------------------------")
print(parrafo_aleatorio)
print("-------------------------------------------")
print(f"Este p치rrafo tiene {len(parrafo_aleatorio.split())} palabras.")# Seleccionamos y mostramos un p치rrafo aleatorio de la Odisea, incluyendo el n칰mero de palabras.

"""## Visualizaciones interesantes

"""

#游 Parte 6: Limpieza del texto y creaci칩n de nube de palabras
# Importamos librer칤as para procesamiento de lenguaje natural y visualizaci칩n.


from wordcloud import WordCloud#Visualizar texto con una nube de palabras
import numpy as np
from PIL import Image#PIL significa Python Imaging Library, y es una de las bibliotecas m치s usadas para procesar im치genes en Python. PIL ya no se actualiza, pero existe una versi칩n moderna llamada Pillow, que es 100% compatible y es la que est치s usando, aunque se importa como PIL.
import nltk#Herramientas generales de PLN
from nltk.corpus import stopwords# Eliminar palabras comunes que no aportan significado (como "el", "la", "y").
import re#Limpiar el texto con expresiones regulares

import matplotlib.pyplot as plt

# Descarga las stopwords en espa침ol
nltk.download('stopwords')
stop_words = set(stopwords.words('spanish'))

# Funci칩n para limpiar y tokenizar el texto

def limpiar_texto(texto):
    # 1. Preparar el texto

    texto_minusculas = texto.lower()# Convertir todo a min칰sculas

    # 2. Eliminar signos de puntuaci칩n
    texto_sin_puntuacion = re.sub(r'[^\w\s]', '', texto_minusculas)# [^\w\s] significa: eliminar todo lo que no sea letra, n칰mero o espacio

    # 3. Dividir el texto en palabras individuales
    lista_palabras = texto_sin_puntuacion.split()

    # 4. Crear lista para almacenar palabras importantes
    palabras_importantes = []

    # 5. Revisar cada palabra y guardar solo las que no son palabras comunes
    for palabra in lista_palabras:
        if palabra not in stop_words:  # stop_words contiene palabras como "el", "la", "y", etc.
            palabras_importantes.append(palabra)

    return palabras_importantes

# Obtener el texto completo de la p치gina web
texto_completo = soup.get_text()

# Limpiar el texto y obtener lista de palabras importantes
palabras_limpias = limpiar_texto(texto_completo)

# Unir todas las palabras importantes en un solo texto, separadas por espacios
texto_limpio = ' '.join(palabras_limpias)

# Funci칩n para normalizar el texto:
# - convierte a min칰sculas
# - elimina signos de puntuaci칩n
# - remueve stopwords
# - descarta palabras adicionales irrelevantes como "canto", "cap칤tulo", etc.

# 4. Nube de palabras mejorada con la forma de un barco griego
wordcloud = WordCloud(width=800, height=400,
                      background_color='black',
                      stopwords=stop_words,
                      contour_width=3,
                      contour_color='steelblue').generate(texto_limpio)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Palabras clave de La Odisea')
plt.show()
# Creamos una nube de palabras a partir del texto procesado, donde el tama침o refleja la frecuencia.

def limpiar_texto(texto):
    # 1. Definir palabras adicionales a eliminar
    palabras_a_eliminar = {
        'dijo', 'as칤', 'aunque', 'sino', 'luego', 'pues', 'mientras',
        'despu칠s', 'antes', 'porque', 'cuando', 'c칩mo', 'donde', 'cap',
        'cap칤tulo', 'verso', 'canto', '치'  # A침ade aqu칤 las palabras que quieras eliminar
    }

    # 2. Combinar stopwords con palabras adicionales a eliminar
    todas_palabras_a_eliminar = stop_words.union(palabras_a_eliminar)

    # 3. Preparar el texto
    texto_minusculas = texto.lower()
    texto_sin_puntuacion = re.sub(r'[^\w\s]', '', texto_minusculas)
    lista_palabras = texto_sin_puntuacion.split()

    # 4. Crear lista para palabras importantes
    palabras_importantes = []

    # 5. Revisar cada palabra
    for palabra in lista_palabras:
        # Guardar solo si no est치 en la lista de palabras a eliminar
        if palabra not in todas_palabras_a_eliminar:
            palabras_importantes.append(palabra)

    return palabras_importantes

# Obtener y limpiar el texto
texto_completo = soup.get_text()
palabras_limpias = limpiar_texto(texto_completo)
texto_limpio = ' '.join(palabras_limpias)

# 4. Nube de palabras mejorada con la forma de un barco griego
wordcloud = WordCloud(width=800, height=400,
                      background_color='black',
                      stopwords=stop_words,
                      contour_width=3,
                      contour_color='steelblue').generate(texto_limpio)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Palabras clave de La Odisea')
plt.show()