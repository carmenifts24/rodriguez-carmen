# -*- coding: utf-8 -*-
"""000_LangExtract.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UDNAy5OHwL8k1W5z1N9PMpICJ2P3dsOX

# Introducci√≥n a la Extracci√≥n de Informaci√≥n con LangExtract

¬°Bienvenidos a la primera clase de Procesamiento del Lenguaje Natural (PLN)!

En este cuaderno, exploraremos una herramienta muy √∫til para la extracci√≥n de informaci√≥n de texto: **LangExtract**. Esta librer√≠a, desarrollada por Google, aprovecha el poder de los modelos de lenguaje grandes como Gemini para identificar y extraer entidades y relaciones espec√≠ficas de un texto de forma estructurada.

Es importante destacar que LangExtract es una *herramienta* que facilita el proceso de extracci√≥n, pero no es una soluci√≥n m√°gica. La calidad de la extracci√≥n depende en gran medida de la definici√≥n clara de la tarea, el dise√±o del prompt y la provisi√≥n de ejemplos de alta calidad.

Este cuaderno servir√° como una demostraci√≥n pr√°ctica de c√≥mo utilizar LangExtract para una tarea de extracci√≥n simple, mostr√°ndoles el flujo de trabajo desde la instalaci√≥n hasta la visualizaci√≥n de los resultados.

Para m√°s detalles sobre LangExtract, pueden consultar la siguiente referencia:
[Introducing LangExtract: A Gemini-powered information extraction library](https://developers.googleblog.com/es/introducing-langextract-a-gemini-powered-information-extraction-library/)
"""

!pip install -U langextract -q
## Instalamos la librer√≠a LangExtract para tareas de extracci√≥n de informaci√≥n usando modelos de lenguaje como Gemini.
#Es una herramienta de alto nivel para extraer entidades y relaciones a partir de texto usando LLMs.

# Importamos librer√≠as necesarias para la extracci√≥n de texto y para acceder a las claves API desde Google Colab.
import textwrap #formatear correctamente strings multil√≠nea (como el prompt), eliminando sangr√≠as innecesarias.
import langextract as lx # es la librer√≠a de Google usada para realizar extracciones de informaci√≥n desde texto usando modelos LLM como Gemini.
import os# os se usa para acceder al sistema de archivos y manejar variables de entorno como la clave API de LangExtract.
from google.colab import userdata # userdata permite acceder de forma segura a claves guardadas como secretos en Google Colab, como la API key de Gemini.

# Intentamos recuperar la clave API de Gemini almacenada como secreto en Colab.
# Si se encuentra, se asigna como variable de entorno para que LangExtract pueda autenticar los requests.

secret_names = ['GEMINI_API_KEY', 'GOOGLE_API_KEY']
api_key_found = False

for sn in secret_names:
    try:
        # Intenta obtener la clave con uno de los nombres posibles
        api_key = userdata.get(sn)

        # Si se encuentra, la asignamos a la variable de entorno que langextract espera
        os.environ['LANGEXTRACT_API_KEY'] = api_key
        print(f"‚úÖ Clave de API cargada exitosamente desde: '{sn}'")
        api_key_found = True
        break # Salimos del bucle una vez que encontramos la clave
    except userdata.SecretNotFoundError:
        # Si no se encuentra, simplemente contin√∫a al siguiente nombre
        continue
    except Exception as e:
        print(f"‚ùóÔ∏è Ocurri√≥ un error inesperado: {e}")
        break

if not api_key_found:
    print("\n‚ùå ERROR: No se pudo encontrar una clave de API.")
    print(f"Aseg√∫rate de haber guardado tu clave en los secretos de Colab con uno de estos nombres: {secret_names}")
    print("And√° al panel izquierdo -> üîë Secretos -> Nuevo secreto.")

# 1. Definimos el prompt (instrucci√≥n) para el modelo. Aqu√≠ especificamos qu√© tipo de informaci√≥n queremos extraer del texto.
#üß† ¬øPor qu√© es importante el prompt?
#LangExtract usa prompts como los LLM tradicionales. La claridad y precisi√≥n del prompt influye directamente en la calidad de las extracciones.

prompt = textwrap.dedent("""\
    Extrae personajes, emociones y relaciones en orden de aparici√≥n.
    Usa el texto exacto para las extracciones. No parafrasees ni superpongas entidades.
    Proporciona atributos significativos para cada entidad para a√±adir contexto.""")

# 2. Proporcionar un ejemplo de alta calidad para guiar al modelo.
# Creamos un ejemplo de entrenamiento para guiar al modelo.
# Especificamos manualmente qu√© entidades y relaciones debe detectar, junto con atributos contextuales.
examples = [
    lx.data.ExampleData(
        text="ROMEO. ¬°Pero, silencio! ¬øQu√© luz alumbra esa ventana? Es el oriente, y Julieta es el sol.",
        extractions=[
            lx.data.Extraction(
                extraction_class="personaje",
                extraction_text="ROMEO",
                attributes={"estado_emocional": "asombro"}
            ),
            lx.data.Extraction(
                extraction_class="emocion",
                extraction_text="¬°Pero, silencio!",
                attributes={"sentimiento": "admiraci√≥n suave"}
            ),
            lx.data.Extraction(
                extraction_class="relacion",
                extraction_text="Julieta es el sol",
                attributes={"tipo": "met√°fora"}
            ),
        ]
    )
]

print("Definici√≥n de la tarea de extracci√≥n creada.")

# El texto de entrada a procesar.
# Texto de entrada sobre el cual se aplicar√° la extracci√≥n autom√°tica.
#input_text = "Si me quieres, qui√©reme entera, no por zonas de luz o sombra‚Ä¶ Si me quieres, qui√©reme negra y blanca, Y gris, verde, y rubia, y morena‚Ä¶ Qui√©reme d√≠a, qui√©reme noche‚Ä¶ ¬°Y madrugada en la ventana abierta!‚Ä¶ Si me quieres, no me recortes: ¬°Qui√©reme toda!‚Ä¶ O no me quieras"

input_text = "Lady Julieta contemplaba con anhelo las estrellas, su coraz√≥n dol√≠a por Romeo"

# Ejecutar la extracci√≥n.
# Nota: Esto har√° una llamada a la API de Gemini, lo cual puede incurrir en costos.
# Ejecutamos la extracci√≥n de informaci√≥n utilizando el modelo "gemini-1.5-flash".
# Esta operaci√≥n env√≠a el texto y el prompt a la API y devuelve una estructura con las entidades encontradas.

result = lx.extract(
    text_or_documents=input_text,
    prompt_description=prompt,
    examples=examples,
    model_id="gemini-1.5-flash", # Modelo r√°pido y eficiente.
)
# Ejecutamos la extracci√≥n de informaci√≥n utilizando el modelo "gemini-1.5-flash".
# Esta operaci√≥n env√≠a el texto y el prompt a la API y devuelve una estructura con las entidades encontradas.


# Imprimir las extracciones para ver el resultado estructurado.
print("Texto de Entrada:")
print(f'"{result.text}"\n')
print("Extracciones Encontradas:")
# Iteramos sobre las extracciones devueltas por el modelo y mostramos:
# - Clase de entidad (personaje, emoci√≥n, relaci√≥n)
# - Texto exacto extra√≠do
# - Atributos adicionales y posici√≥n en el texto
#üß† Esto es muy √∫til si quer√©s usar estos datos luego para entrenamiento de modelos supervisados o para an√°lisis ling√º√≠stico.
for entity in result.extractions:
    print(f"- Clase: {entity.extraction_class}")
    print(f"  Texto: {entity.extraction_text}")
    if entity.attributes:
        print(f"  Atributos: {entity.attributes}")
    if entity.char_interval:
        print(f"  Posici√≥n: ({entity.char_interval.start_pos}-{entity.char_interval.end_pos})\n")

# Guardamos las extracciones en un archivo JSONL y generamos una visualizaci√≥n interactiva en HTML.
# Esto permite explorar gr√°ficamente las entidades extra√≠das sobre el texto.

from IPython.display import display, HTML

# Guardar los resultados en un archivo JSONL en memoria (opcional, pero es un buen h√°bito/buena practica).
# Para la visualizaci√≥n, necesitamos guardar y luego cargar el archivo.
output_dir = "/content/langextract_output"
os.makedirs(output_dir, exist_ok=True)
lx.io.save_annotated_documents([result], output_name="extraction_results.jsonl", output_dir=output_dir)

# Generar el contenido HTML desde el archivo de resultados.
html_content = lx.visualize(f"{output_dir}/extraction_results.jsonl")

# Mostrar la visualizaci√≥n interactiva en la celda de Colab.
display(html_content)

"""¬°Espero que este cuaderno te haya sido √∫til para iniciarte en la extracci√≥n de informaci√≥n con LangExtract y que te motive a explorar m√°s a fondo las capacidades de Google Colab!

Con Colab, podes aprovechar al m√°ximo el potencial de este entorno para tus proyectos de PLN y mucho m√°s.

Para seguir aprendiendo sobre Google Colab y sus funcionalidades, te recomiendo visitar:
[https://medium.com/google-colab](https://medium.com/google-colab)
"""

from IPython.display import YouTubeVideo

video_id = "8VFYs3Ot_aA"
YouTubeVideo(video_id, width=800, height=450)