{"cells":[{"cell_type":"markdown","id":"cell-titulo","metadata":{"id":"cell-titulo"},"source":["# Trabajo Integrador Individual - NLP\n","## \"De Texto Crudo a Insights: Pipeline Completo de An√°lisis de NLP\"\n","\n","**Fecha de entrega**: Jueves 25 de septiembre  \n","**Modalidad**: Individual  \n","**Formato**: Repositorio GitHub con notebook documentado\n","\n","---\n","\n","## Objetivos del Trabajo\n","\n","Este trabajo integrador tiene como objetivo que demuestres tu capacidad de:\n","\n","1. **Construir un corpus textual** siguiendo criterios metodol√≥gicos apropiados\n","2. **Aplicar todo el pipeline de NLP** aprendida durante el curso\n","3. **Comparar diferentes t√©cnicas** de representaci√≥n y an√°lisis textual\n","4. **Interpretar resultados** en el contexto del dominio elegido\n","5. **Documentar y presentar** tu trabajo de manera profesional\n","\n","Al completar este trabajo, tendr√°s una demostraci√≥n tangible de tus habilidades en procesamiento de lenguaje natural que pod√©s incluir en tu portafolio profesional.\n","\n","---"]},{"cell_type":"markdown","source":["## ¬øPor qu√© Cuadernos Interactivos para IA y Ciencias de Datos?\n","\n","### Diferencias Metodol√≥gicas Fundamentales\n","\n","El trabajo en inteligencia artificial y ciencias de datos requiere un enfoque metodol√≥gico diferente al desarrollo de software tradicional. Mientras que la programaci√≥n tradicional sigue un flujo lineal y predecible, el trabajo con datos es inherentemente iterativo y exploratorio.\n","\n","**Programaci√≥n Tradicional:**\n","```\n","Requisitos ‚Üí Dise√±o ‚Üí Implementaci√≥n ‚Üí Testing ‚Üí Producto\n","```\n","\n","**Investigaci√≥n en IA/Datos:**\n","```\n","Hip√≥tesis ‚ü∑ Experimento ‚ü∑ An√°lisis ‚ü∑ Refinamiento ‚ü∑ Nueva Hip√≥tesis\n","```\n","\n","### Ventajas de los Cuadernos Interactivos\n","\n","1. **Narrativa Cient√≠fica:** Permiten documentar el proceso de pensamiento, no solo el resultado final\n","2. **Iteraci√≥n R√°pida:** Ejecutar y modificar secciones espec√≠ficas sin reejecutar todo el programa\n","3. **Visualizaci√≥n Inmediata:** Ver resultados inmediatamente despu√©s de cada paso\n","4. **Comunicaci√≥n Efectiva:** Stakeholders no t√©cnicos pueden seguir el proceso y entender decisiones\n","5. **Reproducibilidad:** Otros investigadores pueden replicar exactamente los experimentos\n","\n","### Casos de Uso en la Industria\n","\n","- **Google Research:** Publica papers con cuadernos que permiten reproducir experimentos\n","- **Netflix:** Usa cuadernos para an√°lisis de datos de usuarios y recomendaciones\n","- **Uber:** An√°lisis de patrones de viajes y optimizaci√≥n de rutas\n","- **Kaggle:** Plataforma completa basada en cuadernos para competencias de machine learning\n","\n","### Cu√°ndo Usar Cada Herramienta\n","\n","**Usar Cuadernos para:**\n","- An√°lisis exploratorio de datos\n","- Experimentaci√≥n y prototipado\n","- Comunicaci√≥n de resultados\n","- Educaci√≥n y documentaci√≥n\n","\n","**Usar Scripts para:**\n","- Sistemas en producci√≥n\n","- Automatizaci√≥n de tareas repetitivas\n","- APIs y servicios web\n","- Pipelines de datos automatizados\n","\n","En este trabajo pr√°ctico, usaremos cuadernos porque estamos en la fase de investigaci√≥n y experimentaci√≥n, donde necesitamos entender los datos, probar diferentes enfoques y documentar nuestros hallazgos.\n","\n","---"],"metadata":{"id":"d6ZQXIe9iSbU"},"id":"d6ZQXIe9iSbU"},{"cell_type":"markdown","id":"cell-parte1","metadata":{"id":"cell-parte1"},"source":["## Parte 1: Construcci√≥n del Corpus\n","\n","### ¬øQu√© es un Corpus?\n","\n","Un **corpus** es una colecci√≥n estructurada y organizada de textos que representa un dominio espec√≠fico del lenguaje. En procesamiento de lenguaje natural, necesitamos datos textuales bien organizados para poder analizarlos de manera sistem√°tica y obtener insights significativos.\n","\n","**Pens√° en un corpus como una \"muestra representativa\"** del tipo de lenguaje que quer√©s estudiar, similar a como un cient√≠fico toma muestras representativas para estudiar un fen√≥meno.\n","\n","### Caracter√≠sticas de un Buen Corpus\n","\n","Para que tu an√°lisis sea exitoso, tu corpus debe cumplir con estas caracter√≠sticas:\n","\n","#### 1. Coherencia Tem√°tica\n","- Los textos deben estar relacionados por **tema**, **g√©nero**, **autor**, **√©poca** o **estilo**\n","- Debe haber un \"hilo conductor\" que justifique por qu√© esos textos van juntos\n","- **Ejemplo**: Todas las canciones de rock nacional argentino, o todos los cuentos de terror contempor√°neo\n","\n","#### 2. Tama√±o Suficiente\n","- **M√≠nimo**: 15-20 documentos para an√°lisis significativo\n","- **√ìptimo**: 20-30 documentos\n","- Cada documento debe tener contenido sustancial (no tweets de 2 l√≠neas)\n","\n","#### 3. Variabilidad Interna\n","- Aunque coherente, debe haber **diferencias** entre los textos\n","- Esta variabilidad permite encontrar patrones interesantes\n","- **Ejemplo**: Canciones del mismo g√©nero pero de diferentes d√©cadas\n","\n","#### 4. Calidad Textual\n","- Textos **completos**, no fragmentos muy cortos\n","- **Legibles** y bien formateados\n","- **Sin errores** de codificaci√≥n o caracteres extra√±os\n","\n","### Opciones de Corpus que Pod√©s Elegir\n","\n","Eleg√≠ **UNA** de estas opciones o propon√© una similar:"]},{"cell_type":"markdown","id":"cell-opciones-corpus","metadata":{"id":"cell-opciones-corpus"},"source":["#### Opci√≥n A: Corpus Musical üéµ\n","\n","**Posibilidades**:\n","- Letras de canciones de un **g√©nero espec√≠fico** (rock nacional, tango, trap argentino, folklore)\n","- Canciones de una **√©poca determinada** (a√±os 80, d√©cada del 2000, m√∫sica actual)\n","- Obra de **artistas relacionados** (Charly Garc√≠a, Luis Alberto Spinetta, Fito P√°ez)\n","- Canciones sobre un **tema espec√≠fico** (amor, protesta social, Buenos Aires)\n","\n","**Requerimientos**: M√≠nimo 20-25 canciones completas\n","\n","**Fuentes sugeridas**: Genius.com, LyricFind, sitios oficiales de artistas, Rock.com.ar\n","\n","**Ejemplo de pregunta de investigaci√≥n**: \"¬øC√≥mo evolucion√≥ el vocabulario del rock nacional argentino entre los 80 y la actualidad?\"\n","\n","---\n","\n","#### Opci√≥n B: Corpus Literario üìö\n","\n","**Posibilidades**:\n","- **Cuentos cortos** de un autor (Borges, Cort√°zar, Silvina Ocampo)\n","- **Poemas** de diferentes autores argentinos o latinoamericanos\n","- **Microrrelatos** contempor√°neos\n","- **Cr√≥nicas** de un autor espec√≠fico (Caparr√≥s, Villoro, Monterroso)\n","\n","**Requerimientos**: M√≠nimo 15-20 textos completos\n","\n","**Fuentes sugeridas**: Biblioteca Digital Argentina, Cervantes Virtual, Project Gutenberg (espa√±ol), Ciudad Seva\n","\n","**Ejemplo de pregunta de investigaci√≥n**: \"¬øQu√© diferencias estil√≠sticas se pueden identificar entre los cuentos de Borges y Cort√°zar?\"\n","\n","---\n","\n","#### Opci√≥n C: Corpus Period√≠stico üì∞\n","\n","**Posibilidades**:\n","- **Art√≠culos de opini√≥n** sobre un tema (deporte, pol√≠tica, cultura, tecnolog√≠a)\n","- **Cr√≥nicas** de un medio espec√≠fico (P√°gina/12, La Naci√≥n, Clar√≠n)\n","- **Rese√±as** de un tipo espec√≠fico (libros, pel√≠culas, restaurantes, m√∫sica)\n","- **Editoriales** sobre acontecimientos importantes\n","\n","**Requerimientos**: M√≠nimo 20-25 art√≠culos\n","\n","**Fuentes sugeridas**: Sitios web de diarios argentinos, revistas culturales, blogs period√≠sticos\n","\n","**Ejemplo de pregunta de investigaci√≥n**: \"¬øC√≥mo difiere el lenguaje usado en rese√±as positivas vs negativas de restaurantes?\"\n","\n","---\n","\n","#### Opci√≥n D: Corpus Digital üíª\n","\n","**Posibilidades**:\n","- **Publicaciones de blog** sobre un tema espec√≠fico (viajes, cocina, tecnolog√≠a, deportes)\n","- **Rese√±as de productos** de una categor√≠a (libros en Goodreads, productos en MercadoLibre)\n","- **Posts de LinkedIn** de profesionales de un sector\n","- **Transcripciones** de podcasts argentinos\n","\n","**Requerimientos**: M√≠nimo 25-30 textos\n","\n","**Fuentes sugeridas**: Plataformas de rese√±as, blogs p√∫blicos, redes sociales profesionales\n","\n","**Ejemplo de pregunta de investigaci√≥n**: \"¬øQu√© caracter√≠sticas del lenguaje distinguen las rese√±as de productos exitosas de las menos √∫tiles?\""]},{"cell_type":"markdown","id":"cell-construccion","metadata":{"id":"cell-construccion"},"source":["### Consideraciones para la Construcci√≥n del Corpus\n","\n","#### Aspectos √âticos y Legales ‚öñÔ∏è\n","\n","**MUY IMPORTANTE**: Respet√° siempre estos principios:\n","\n","1. **Usar solo fuentes p√∫blicas y gratuitas**\n","   - No usar contenido de pago o con restricciones\n","   - Verificar que el contenido sea de acceso libre\n","\n","2. **Respetar derechos de autor**\n","   - Citar todas las fuentes correctamente\n","   - Para an√°lisis acad√©mico, generalmente es \"fair use\"\n","   - No redistribuir los textos completos p√∫blicamente\n","\n","3. **No incluir informaci√≥n privada o sensible**\n","   - Evitar datos personales de individuos privados\n","   - No usar conversaciones privadas o informaci√≥n confidencial\n","\n","#### Aspectos T√©cnicos üõ†Ô∏è\n","\n","**Formato est√°ndar para organizar tu corpus**:\n","\n","```\n","mi_corpus/\n","‚îú‚îÄ‚îÄ raw_texts/\n","‚îÇ   ‚îú‚îÄ‚îÄ 01_titulo_descriptivo.txt\n","‚îÇ   ‚îú‚îÄ‚îÄ 02_titulo_descriptivo.txt\n","‚îÇ   ‚îú‚îÄ‚îÄ ...\n","‚îÇ   ‚îî‚îÄ‚îÄ 25_titulo_descriptivo.txt\n","‚îî‚îÄ‚îÄ metadata.csv\n","```\n","\n","**Especificaciones t√©cnicas**:\n","- **Un archivo .txt por documento**\n","- **Naming consistente**: `01_titulo.txt`, `02_titulo.txt`, etc.\n","- **Codificaci√≥n UTF-8** para manejar acentos y caracteres especiales\n","- **Solo texto plano**, sin formato HTML o markdown\n","\n","#### Metadatos Obligatorios üìä\n","\n","Cre√° un archivo `metadata.csv` con esta informaci√≥n m√≠nima:\n","\n","| archivo | titulo | autor_fuente | fecha | categoria | palabras_aprox |\n","|---------|--------|--------------|-------|-----------|----------------|\n","| 01_titulo.txt | \"T√≠tulo completo\" | \"Autor/Fuente\" | \"2023-09-15\" | \"rock\" | 150 |\n","| 02_titulo.txt | \"Otro t√≠tulo\" | \"Otro autor\" | \"2023-08-20\" | \"rock\" | 200 |\n","\n","**Columnas obligatorias**:\n","- `archivo`: Nombre del archivo de texto\n","- `titulo`: T√≠tulo del documento\n","- `autor_fuente`: Autor o fuente del texto\n","- `fecha`: Fecha de publicaci√≥n (aproximada si no sab√©s exacta)\n","- `categoria`: Categor√≠a o subtipo (si aplicable)\n","- `palabras_aprox`: N√∫mero aproximado de palabras\n","\n","#### Aspectos Metodol√≥gicos üî¨\n","\n","**Preguntas que ten√©s que poder responder**:\n","\n","1. **¬øPor qu√© elegiste estos textos espec√≠ficos?**\n","   - Criterios de selecci√≥n claros\n","   - Justificaci√≥n de inclusi√≥n/exclusi√≥n\n","\n","2. **¬øLos textos representan bien el dominio elegido?**\n","   - Cobertura adecuada del tema/g√©nero/√©poca\n","   - Balance entre diferentes subtipos si aplicable\n","\n","3. **¬øQu√© variabilidad esper√°s encontrar?**\n","   - Diferencias y similitudes anticipadas\n","   - Hip√≥tesis sobre patrones que podr√≠as descubrir"]},{"cell_type":"markdown","id":"cell-fuentes","metadata":{"id":"cell-fuentes"},"source":["### Fuentes Recomendadas por Tipo de Corpus\n","\n","#### Para Corpus Musical üéµ\n","- **Genius.com**: Base de datos masiva de letras con informaci√≥n detallada\n","- **LyricFind**: Letras verificadas y oficiales\n","- **Rock.com.ar**: Espec√≠fico para rock nacional argentino\n","- **Sitios oficiales** de artistas o discogr√°ficas\n","- **LastFM**: Letras y metadatos de canciones\n","\n","#### Para Corpus Literario üìö\n","- **Cervantes Virtual**: Biblioteca digital en espa√±ol\n","- **Biblioteca Digital Argentina**: Textos de autores argentinos\n","- **Project Gutenberg** (secci√≥n espa√±ol): Cl√°sicos de dominio p√∫blico\n","- **Ciudad Seva**: Cuentos y textos cortos\n","- **Wikisource**: Textos libres colaborativos\n","\n","#### Para Corpus Period√≠stico üì∞\n","- **P√°gina/12**: Archivo web de art√≠culos\n","- **La Naci√≥n**: Secci√≥n de opini√≥n y cultura\n","- **Clar√≠n**: Archivo de notas y columnas\n","- **Perfil**: Art√≠culos de an√°lisis pol√≠tico y cultural\n","- **Infobae**: Variedad de temas y secciones\n","\n","#### Para Corpus Digital üíª\n","- **Goodreads**: Rese√±as de libros en espa√±ol\n","- **TripAdvisor**: Rese√±as de lugares y servicios\n","- **Blogs especializados**: En el tema que elijas\n","- **LinkedIn**: Posts profesionales p√∫blicos\n","- **Reddit** (subreddits argentinos): Discusiones tem√°ticas\n","\n","### Herramientas T√©cnicas para Recolecci√≥n\n","\n","#### Recolecci√≥n Manual (Recomendado para principiantes)\n","- **Copy-paste** desde sitios web\n","- **Guardar como texto** desde navegadores\n","- **Organizar** manualmente en carpetas\n","\n","#### Recolecci√≥n Semi-automatizada (Para m√°s avanzados)\n","```python\n","import requests\n","from bs4 import BeautifulSoup\n","# C√≥digo para extraer texto de p√°ginas web\n","# Solo si ten√©s experiencia con web scraping\n","```\n","\n","#### APIs Disponibles (Opcionales)\n","- **Genius API**: Para letras de canciones\n","- **NewsAPI**: Para art√≠culos period√≠sticos\n","- **Reddit API**: Para posts de reddit\n","\n","**Nota**: Si us√°s APIs o web scraping, asegurate de respetar los t√©rminos de servicio y l√≠mites de velocidad."]},{"cell_type":"markdown","id":"cell-parte2","metadata":{"id":"cell-parte2"},"source":["---\n","\n","## Parte 2: An√°lisis T√©cnico - Estructura del Notebook\n","\n","Tu notebook principal debe tener **exactamente** estas secciones, en este orden:"]},{"cell_type":"markdown","id":"cell-seccion1","metadata":{"id":"cell-seccion1"},"source":["### Secci√≥n 1: Presentaci√≥n del Corpus (15% de la nota)\n","\n","```python\n","# T√≠tulo: \"An√°lisis de [Tu Corpus]: [Pregunta de Investigaci√≥n]\"\n","\n","# 1.1 Descripci√≥n del corpus elegido\n","# - Qu√© tipo de textos incluye\n","# - Cu√°ntos documentos\n","# - Per√≠odo temporal abarcado\n","# - Fuentes utilizadas\n","\n","# 1.2 Justificaci√≥n de la elecci√≥n\n","# - Por qu√© elegiste este corpus\n","# - Qu√© te interesa descubrir\n","# - Qu√© hip√≥tesis ten√©s sobre lo que vas a encontrar\n","\n","# 1.3 Proceso de recolecci√≥n\n","# - C√≥mo obtuviste los textos\n","# - Criterios de inclusi√≥n/exclusi√≥n\n","# - Dificultades encontradas y c√≥mo las resolviste\n","\n","# 1.4 Estad√≠sticas b√°sicas\n","# - N√∫mero total de textos\n","# - N√∫mero total de palabras (aproximado)\n","# - Distribuci√≥n de tama√±os de documentos\n","# - Gr√°fico de distribuci√≥n temporal (si aplicable)\n","\n","# 1.5 Exploraci√≥n inicial\n","# - Mostrar fragmentos representativos\n","# - Primeras observaciones cualitativas\n","# - Nube de palabras inicial (opcional)\n","```"]},{"cell_type":"markdown","id":"cell-seccion2","metadata":{"id":"cell-seccion2"},"source":["### Secci√≥n 2: Preprocesamiento (20% de la nota)\n","\n","```python\n","# 2.1 Carga y organizaci√≥n de datos\n","import pandas as pd\n","import numpy as np\n","import pickle\n","import re\n","import string\n","from collections import Counter\n","\n","# - C√≥digo para cargar todos los archivos de texto\n","# - Integraci√≥n con metadatos\n","# - Verificaci√≥n de integridad de datos\n","\n","# 2.2 Limpieza de texto\n","# - Aplicar t√©cnicas vistas en clase:\n","#   * Conversi√≥n a min√∫sculas\n","#   * Eliminaci√≥n de signos de puntuaci√≥n\n","#   * Eliminaci√≥n de n√∫meros (si no son relevantes)\n","#   * Eliminaci√≥n de caracteres especiales\n","# - Justificar cada decisi√≥n de limpieza\n","\n","# 2.3 Tokenizaci√≥n y normalizaci√≥n\n","# - Separar texto en palabras\n","# - Decidir si aplicar stemming o lemmatizaci√≥n (justificar)\n","# - Mostrar ejemplos de antes y despu√©s\n","\n","# 2.4 Manejo de stop words\n","import nltk\n","nltk.download('stopwords')\n","# - Decidir qu√© stop words usar (espa√±ol est√°ndar + espec√≠ficas del dominio)\n","# - Mostrar impacto de eliminar stop words\n","# - Justificar decisiones\n","\n","# 2.5 Estad√≠sticas post-procesamiento\n","# - Vocabulario final (n√∫mero de palabras √∫nicas)\n","# - Distribuci√≥n de frecuencias\n","# - Comparaci√≥n antes/despu√©s del preprocesamiento\n","```"]},{"cell_type":"markdown","id":"cell-seccion3","metadata":{"id":"cell-seccion3"},"source":["### Secci√≥n 3: An√°lisis con BoW/TF-IDF (25% de la nota)\n","\n","```python\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 3.1 Vectorizaci√≥n del corpus\n","# - Crear matriz documento-t√©rmino con CountVectorizer\n","# - Crear matriz TF-IDF\n","# - Mostrar dimensiones y caracter√≠sticas de las matrices\n","# - Explicar qu√© representan los n√∫meros\n","\n","# 3.2 T√©rminos m√°s frecuentes y distintivos\n","# - Top 20 palabras m√°s frecuentes (BoW)\n","# - Top 20 t√©rminos con mayor TF-IDF\n","# - Comparar ambas listas: ¬øqu√© diferencias ves?\n","# - Interpretaci√≥n: ¬øestos t√©rminos caracterizan bien tu corpus?\n","\n","# 3.3 Matriz de similitud entre documentos\n","# - Calcular similitud coseno entre todos los pares de documentos\n","# - Encontrar los 2-3 pares m√°s similares\n","# - Encontrar los 2-3 pares m√°s diferentes\n","# - Analizar: ¬øtiene sentido lo que encontraste?\n","\n","# 3.4 Visualizaci√≥n\n","# - Nube de palabras con t√©rminos m√°s importantes\n","# - Gr√°fico de barras con t√©rminos m√°s frecuentes\n","# - Heatmap de similitud entre documentos (si no son demasiados)\n","\n","# 3.5 Interpretaci√≥n de resultados\n","# - ¬øQu√© patrones encontr√°s en tu corpus?\n","# - ¬øLos documentos similares realmente parecen similares?\n","# - ¬øHay agrupaciones naturales en tus datos?\n","# - ¬øQu√© limitaciones ves en este enfoque?\n","```"]},{"cell_type":"markdown","id":"cell-seccion4","metadata":{"id":"cell-seccion4"},"source":["### Secci√≥n 4: An√°lisis con Word Embeddings (25% de la nota)\n","\n","```python\n","import spacy\n","# Cargar modelo en espa√±ol\n","nlp = spacy.load(\"es_core_news_md\")\n","\n","# 4.1 Aplicaci√≥n de embeddings\n","# - Procesar tu corpus con spaCy\n","# - Obtener vectores para documentos (promedio de vectores de palabras)\n","# - Explicar qu√© son los embeddings y por qu√© son diferentes a BoW\n","\n","# 4.2 An√°lisis de similitud sem√°ntica\n","# - Calcular similitud entre documentos usando embeddings\n","# - Comparar con resultados de TF-IDF\n","# - ¬øQu√© documentos son m√°s similares seg√∫n embeddings?\n","# - ¬øCoinciden los resultados con TF-IDF?\n","\n","# 4.3 B√∫squeda de analog√≠as relevantes al corpus\n","# - Encontrar palabras m√°s similares a t√©rminos clave de tu dominio\n","# - Intentar crear 2-3 analog√≠as que funcionen con vocabulario de tu corpus\n","# - Ejemplo: \"rock es a guitarra como tango es a ?\"\n","# - Interpretar: ¬ølas analog√≠as tienen sentido?\n","\n","# 4.4 Comparaci√≥n con resultados de BoW\n","# - Crear tabla comparativa de documentos m√°s similares\n","# - ¬øQu√© m√©todo da resultados m√°s intuitivos?\n","# - ¬øEn qu√© casos embeddings es claramente superior?\n","# - ¬øEn qu√© casos BoW podr√≠a ser suficiente?\n","\n","# 4.5 Visualizaci√≥n de embeddings (si es posible)\n","# - Intentar reducir dimensionalidad (PCA o t-SNE)\n","# - Graficar documentos en 2D\n","# - ¬øSe ven agrupaciones naturales?\n","# (Esta parte es opcional si resulta muy compleja)\n","```"]},{"cell_type":"markdown","id":"cell-seccion5","metadata":{"id":"cell-seccion5"},"source":["### Secci√≥n 5: An√°lisis Complementario (10% de la nota)\n","\n","**Eleg√≠ UNA de estas tres opciones** seg√∫n lo que hayan visto en clase:\n","\n","#### Opci√≥n A: POS Tagging y An√°lisis Gramatical\n","```python\n","# - Analizar distribuci√≥n de tipos de palabras (sustantivos, verbos, adjetivos)\n","# - ¬øHay diferencias gramaticales entre subcategor√≠as de tu corpus?\n","# - Interpretaci√≥n estil√≠stica de los patrones encontrados\n","```\n","\n","#### Opci√≥n B: An√°lisis de Sentimientos\n","```python\n","# - Aplicar an√°lisis de sentimientos a tus textos\n","# - ¬øCu√°les son los m√°s positivos/negativos?\n","# - ¬øHay patrones de sentimiento por categor√≠a/autor/√©poca?\n","```\n","\n","#### Opci√≥n C: Extracci√≥n B√°sica de Entidades\n","```python\n","# - Usar spaCy para extraer entidades nombradas (si aplicable a tu corpus)\n","# - ¬øQu√© personas, lugares, organizaciones se mencionan m√°s?\n","# - ¬øHay diferencias entre subcategor√≠as de tu corpus?\n","```"]},{"cell_type":"markdown","id":"cell-seccion6","metadata":{"id":"cell-seccion6"},"source":["### Secci√≥n 6: Conclusiones y Reflexiones (5% de la nota)\n","\n","```python\n","# 6.1 Hallazgos principales sobre el corpus\n","# - ¬øQu√© descubriste sobre tu corpus que no sab√≠as antes?\n","# - ¬øSe confirmaron tus hip√≥tesis iniciales?\n","# - ¬øQu√© te sorprendi√≥ m√°s?\n","\n","# 6.2 Comparaci√≥n de m√©todos utilizados\n","# - ¬øQu√© t√©cnica te pareci√≥ m√°s √∫til para tu tipo de corpus?\n","# - ¬øCu√°ndo usar√≠as BoW/TF-IDF vs embeddings?\n","# - ¬øQu√© ventajas y desventajas encontraste en cada m√©todo?\n","\n","# 6.3 Limitaciones encontradas\n","# - ¬øQu√© no pudiste capturar con las t√©cnicas usadas?\n","# - ¬øQu√© aspectos importantes de tu corpus quedan sin analizar?\n","# - ¬øQu√© mejorar√≠as si tuvieras m√°s tiempo/recursos?\n","\n","# 6.4 Aplicaciones potenciales del an√°lisis\n","# - ¬øC√≥mo se podr√≠a usar este an√°lisis en un contexto real?\n","# - ¬øQu√© valor agregado proporciona?\n","# - ¬øQu√© otros an√°lisis te gustar√≠a hacer en el futuro?\n","```"]},{"cell_type":"markdown","id":"cell-entrega","metadata":{"id":"cell-entrega"},"source":["---\n","\n","## Parte 3: Especificaciones de Entrega\n","\n","### Estructura del Repositorio GitHub\n","\n","Tu repositorio debe tener **exactamente** esta estructura:\n","\n","```\n","apellido-nombre-nlp-integrador/\n","‚îú‚îÄ‚îÄ README.md                          # Descripci√≥n del proyecto\n","‚îú‚îÄ‚îÄ corpus/\n","‚îÇ   ‚îú‚îÄ‚îÄ raw_texts/                     # Textos originales\n","‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_texto.txt\n","‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_texto.txt\n","‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...\n","‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ XX_texto.txt\n","‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                   # Informaci√≥n de los textos\n","‚îÇ   ‚îî‚îÄ‚îÄ processed/                     # Datos procesados (opcional)\n","‚îÇ       ‚îî‚îÄ‚îÄ corpus_limpio.pkl\n","‚îú‚îÄ‚îÄ notebooks/\n","‚îÇ   ‚îî‚îÄ‚îÄ analisis_integrador.ipynb     # Notebook principal\n","‚îú‚îÄ‚îÄ visualizations/                   # Gr√°ficos generados\n","‚îÇ   ‚îú‚îÄ‚îÄ nube_palabras.png\n","‚îÇ   ‚îú‚îÄ‚îÄ frecuencias.png\n","‚îÇ   ‚îî‚îÄ‚îÄ similitud_docs.png\n","‚îî‚îÄ‚îÄ requirements.txt                   # Dependencias necesarias\n","```\n","\n","### README.md Obligatorio\n","\n","Tu README debe incluir **exactamente** esta informaci√≥n:\n","\n","```markdown\n","# An√°lisis de NLP: [T√≠tulo Descriptivo de Tu Corpus]\n","\n","## Descripci√≥n\n","Breve descripci√≥n (2-3 p√°rrafos) del corpus elegido, objetivos del an√°lisis,\n","y principales hallazgos encontrados.\n","\n","## Informaci√≥n del Corpus\n","- **Tipo**: [M√∫sica/Literatura/Periodismo/Digital]\n","- **Tama√±o**: X textos, aproximadamente Y palabras totales\n","- **Fuentes principales**: [Listar las fuentes m√°s importantes]\n","- **Per√≠odo temporal**: [Si aplicable]\n","- **Criterios de selecci√≥n**: [Brevemente explicar por qu√© elegiste estos textos]\n","\n","## T√©cnicas de NLP Aplicadas\n","- Preprocesamiento de texto (limpieza, tokenizaci√≥n, stop words)\n","- An√°lisis con Bag of Words (BoW) y TF-IDF\n","- An√°lisis con Word Embeddings (spaCy)\n","- [T√©cnica complementaria aplicada: POS/Sentiment/NER]\n","\n","## Principales Hallazgos\n","- [Hallazgo m√°s importante #1]\n","- [Hallazgo m√°s importante #2]\n","- [Hallazgo m√°s importante #3]\n","- [Comparaci√≥n entre m√©todos: cu√°l funcion√≥ mejor y por qu√©]\n","\n","## Tecnolog√≠as Utilizadas\n","- Python 3.x\n","- pandas, numpy\n","- scikit-learn\n","- spaCy\n","- matplotlib, seaborn\n","- [Otras librer√≠as espec√≠ficas que hayas usado]\n","\n","## Instrucciones de Reproducci√≥n\n","1. Clonar este repositorio\n","2. Instalar dependencias: `pip install -r requirements.txt`\n","3. Ejecutar el notebook: `jupyter notebook notebooks/analisis_integrador.ipynb`\n","\n","## Limitaciones y Trabajo Futuro\n","- [Principal limitaci√≥n encontrada]\n","- [Qu√© an√°lisis te gustar√≠a hacer en el futuro]\n","\n","## Autor\n","[Tu nombre] - [Tu email o GitHub]\n","Trabajo Integrador - NLP - [Fecha]\n","```\n","\n","### Archivo requirements.txt\n","\n","Inclu√≠ todas las librer√≠as que usaste:\n","\n","```\n","pandas>=1.3.0\n","numpy>=1.21.0\n","scikit-learn>=1.0.0\n","spacy>=3.4.0\n","matplotlib>=3.5.0\n","seaborn>=0.11.0\n","nltk>=3.7.0\n","wordcloud>=1.8.0\n","jupyter>=1.0.0\n","```"]},{"cell_type":"markdown","id":"cell-evaluacion","metadata":{"id":"cell-evaluacion"},"source":["---\n","\n","## Criterios de Evaluaci√≥n\n","\n","### Construcci√≥n del Corpus (25%)\n","\n","**Excelente (23-25 puntos)**:\n","- Corpus coherente tem√°ticamente y bien justificado\n","- Tama√±o apropiado y textos de buena calidad\n","- Metadatos completos y organizados\n","- Consideraciones √©ticas respetadas\n","- Criterios de selecci√≥n claros y bien argumentados\n","\n","**Bueno (18-22 puntos)**:\n","- Corpus adecuado con justificaci√≥n razonable\n","- Tama√±o suficiente, calidad aceptable\n","- Metadatos mayormente completos\n","- Aspectos √©ticos considerados\n","\n","**Suficiente (13-17 puntos)**:\n","- Corpus b√°sico pero funcional\n","- Tama√±o m√≠nimo, calidad variable\n","- Metadatos incompletos\n","- Justificaci√≥n superficial\n","\n","**Insuficiente (0-12 puntos)**:\n","- Corpus inadecuado o muy peque√±o\n","- Sin metadatos o muy incompletos\n","- Sin justificaci√≥n clara\n","- Problemas √©ticos no considerados\n","\n","### Aplicaci√≥n T√©cnica (50%)\n","\n","**Excelente (45-50 puntos)**:\n","- Preprocesamiento apropiado y bien justificado\n","- BoW/TF-IDF implementado correctamente con interpretaci√≥n profunda\n","- Word embeddings aplicados apropiadamente\n","- Comparaciones metodol√≥gicas claras y fundamentadas\n","- C√≥digo limpio, comentado y reproducible\n","\n","**Bueno (35-44 puntos)**:\n","- T√©cnicas aplicadas correctamente\n","- Interpretaci√≥n adecuada de resultados\n","- Algunas comparaciones entre m√©todos\n","- C√≥digo funcional y documentado\n","\n","**Suficiente (25-34 puntos)**:\n","- Implementaci√≥n b√°sica de t√©cnicas\n","- Interpretaci√≥n superficial\n","- C√≥digo funciona pero con pocos comentarios\n","\n","**Insuficiente (0-24 puntos)**:\n","- Implementaci√≥n incorrecta o incompleta\n","- Sin interpretaci√≥n de resultados\n","- C√≥digo no funcional o no reproducible\n","\n","### An√°lisis e Interpretaci√≥n (15%)\n","\n","**Excelente (14-15 puntos)**:\n","- Insights originales y bien fundamentados\n","- Conexi√≥n clara entre resultados y contexto del corpus\n","- Reflexi√≥n cr√≠tica sobre m√©todos y limitaciones\n","- Conclusiones bien argumentadas\n","\n","**Bueno (11-13 puntos)**:\n","- An√°lisis adecuado con algunas conexiones interesantes\n","- Interpretaci√≥n contextualizada\n","- Algunas reflexiones sobre limitaciones\n","\n","**Suficiente (8-10 puntos)**:\n","- An√°lisis b√°sico y descriptivo\n","- Poca conexi√≥n con contexto\n","- Conclusiones superficiales\n","\n","**Insuficiente (0-7 puntos)**:\n","- Sin an√°lisis real de resultados\n","- Sin interpretaci√≥n contextual\n","- Sin conclusiones claras\n","\n","### Presentaci√≥n y Organizaci√≥n (10%)\n","\n","**Excelente (9-10 puntos)**:\n","- Repositorio GitHub perfectamente organizado\n","- README completo e informativo\n","- Notebook claro, bien estructurado y documentado\n","- Visualizaciones efectivas y bien dise√±adas\n","\n","**Bueno (7-8 puntos)**:\n","- Organizaci√≥n adecuada\n","- README informativo\n","- Notebook claro\n","- Buenas visualizaciones\n","\n","**Suficiente (5-6 puntos)**:\n","- Organizaci√≥n b√°sica\n","- README incompleto\n","- Notebook funcional pero poco claro\n","\n","**Insuficiente (0-4 puntos)**:\n","- Desorganizado o incompleto\n","- Sin README o muy pobre\n","- Notebook confuso o no funcional"]},{"cell_type":"markdown","id":"cell-cronograma","metadata":{"id":"cell-cronograma"},"source":["---\n","\n","## Cronograma Sugerido\n","\n","Para completar exitosamente este trabajo en el tiempo disponible, segu√≠ este cronograma:\n","\n","### D√≠as 1-2: Construcci√≥n del Corpus (Fin de semana)\n","**Objetivos**: Tener corpus completo y organizado\n","\n","**Tareas**:\n","- [ ] Decidir tema y tipo de corpus\n","- [ ] Identificar fuentes espec√≠ficas\n","- [ ] Recolectar 20-30 textos\n","- [ ] Organizar archivos seg√∫n estructura requerida\n","- [ ] Crear archivo metadata.csv completo\n","- [ ] Subir corpus inicial a GitHub\n","- [ ] Verificar que todo funciona correctamente\n","\n","**Tiempo estimado**: 4-5 horas total\n","\n","### D√≠as 3-4: Preprocesamiento y BoW (Lunes-Martes)\n","**Objetivos**: Tener an√°lisis BoW/TF-IDF completo\n","\n","**Tareas**:\n","- [ ] Crear notebook con estructura base\n","- [ ] Implementar carga y limpieza de datos\n","- [ ] Aplicar preprocesamiento completo\n","- [ ] Implementar an√°lisis BoW y TF-IDF\n","- [ ] Crear visualizaciones b√°sicas\n","- [ ] Interpretar primeros resultados\n","\n","**Tiempo estimado**: 3-4 horas total\n","\n","### D√≠a 5: Embeddings y An√°lisis Complementario (Mi√©rcoles)\n","**Objetivos**: Completar an√°lisis t√©cnico\n","\n","**Tareas**:\n","- [ ] Implementar an√°lisis con embeddings\n","- [ ] Comparar resultados con BoW/TF-IDF\n","- [ ] Aplicar t√©cnica complementaria elegida\n","- [ ] Generar visualizaciones finales\n","- [ ] Documentar c√≥digo con comentarios\n","\n","**Tiempo estimado**: 2-3 horas total\n","\n","### D√≠a 6-7: Documentaci√≥n y Entrega Final (Mi√©rcoles-Jueves)\n","**Objetivos**: Finalizar documentaci√≥n y entregar\n","\n","**Tareas**:\n","- [ ] Escribir secci√≥n de conclusiones\n","- [ ] Completar README.md\n","- [ ] Crear requirements.txt\n","- [ ] Revisar notebook completo (ejecutar de principio a fin)\n","- [ ] Verificar que repositorio est√© bien organizado\n","- [ ] Hacer commit final y verificar entrega\n","\n","**Tiempo estimado**: 1-2 horas total\n","\n","### Tiempo Total Estimado: 10-14 horas\n","\n","**Distribuci√≥n sugerida**:\n","- Fin de semana: 5 horas (corpus)\n","- Lunes-Martes: 1.5-2 horas por d√≠a (an√°lisis BoW)\n","- Mi√©rcoles: 2-3 horas (embeddings)\n","- Jueves: 1 hora final (documentaci√≥n y entrega)"]},{"cell_type":"markdown","id":"cell-recursos","metadata":{"id":"cell-recursos"},"source":["---\n","\n","## Recursos de Apoyo\n","\n","### Tutoriales de GitHub (Obligatorio revisar)\n","\n","Si no ten√©s experiencia con GitHub, **es fundamental** que revises estos tutoriales:\n","\n","1. **[Crear cuenta en GitHub](https://github.com/join)**\n","2. **[Crear un repositorio](https://docs.github.com/es/get-started/quickstart/create-a-repo)**\n","3. **[Subir archivos a GitHub](https://docs.github.com/es/repositories/working-with-files/managing-files/adding-a-file-to-a-repository)**\n","4. **[Escribir un buen README](https://docs.github.com/es/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes)**\n","\n","### Herramientas Recomendadas\n","\n","#### Para trabajar con GitHub:\n","- **GitHub Desktop**: Interfaz gr√°fica f√°cil de usar\n","- **VS Code**: Editor que integra bien con GitHub\n","- **Navegador web**: Para subir archivos directamente\n","\n","#### Para desarrollo:\n","- **Google Colab**: Para desarrollar el notebook (gratis)\n","- **Jupyter Lab**: Si prefer√≠s trabajar localmente\n","- **Anaconda**: Para gestionar librer√≠as Python\n","\n","### Librer√≠as Python Esenciales\n","\n","Asegurate de tener instaladas estas librer√≠as:\n","\n","```python\n","# Para instalar todas juntas:\n","!pip install pandas numpy scikit-learn spacy matplotlib seaborn nltk wordcloud\n","\n","# Para descargar modelos de spaCy:\n","!python -m spacy download es_core_news_md\n","\n","# Para descargar recursos de NLTK:\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","```\n","\n","### Templates y C√≥digos de Ejemplo\n","\n","#### Template b√°sico para cargar corpus:\n","```python\n","import os\n","import pandas as pd\n","\n","def cargar_corpus(directorio_textos, archivo_metadata):\n","    \"\"\"Cargar corpus desde directorio de textos y archivo de metadatos\"\"\"\n","    # Cargar metadatos\n","    metadata = pd.read_csv(archivo_metadata)\n","    \n","    # Cargar textos\n","    textos = {}\n","    for _, row in metadata.iterrows():\n","        archivo_path = os.path.join(directorio_textos, row['archivo'])\n","        with open(archivo_path, 'r', encoding='utf-8') as f:\n","            textos[row['archivo']] = f.read()\n","    \n","    return textos, metadata\n","```\n","\n","#### Template para preprocesamiento:\n","```python\n","import re\n","import string\n","from nltk.corpus import stopwords\n","\n","def limpiar_texto(texto):\n","    \"\"\"Aplicar preprocesamiento b√°sico a texto\"\"\"\n","    # Convertir a min√∫sculas\n","    texto = texto.lower()\n","    \n","    # Eliminar signos de puntuaci√≥n\n","    texto = re.sub(f'[{re.escape(string.punctuation)}]', ' ', texto)\n","    \n","    # Eliminar n√∫meros\n","    texto = re.sub(r'\\d+', ' ', texto)\n","    \n","    # Eliminar espacios extra\n","    texto = re.sub(r'\\s+', ' ', texto).strip()\n","    \n","    return texto\n","```\n","\n","**Caracter√≠sticas de trabajos exitosos anteriores**:\n","- Corpus bien justificado y coherente\n","- An√°lisis t√©cnico correcto con interpretaci√≥n contextual\n","- Comparaciones claras entre m√©todos\n","- Documentaci√≥n completa y profesional\n","- Conclusiones fundamentadas y reflexivas"]},{"cell_type":"markdown","id":"cell-preguntas-frecuentes","metadata":{"id":"cell-preguntas-frecuentes"},"source":["---\n","\n","## Preguntas Frecuentes (FAQ)\n","\n","### Sobre la Construcci√≥n del Corpus\n","\n","**P: ¬øPuedo usar textos en ingl√©s?**  \n","R: No, el corpus debe ser en espa√±ol. El modelo de spaCy y las stop words est√°n optimizados para espa√±ol.\n","\n","**P: ¬øQu√© hago si no encuentro suficientes textos de un tema?**  \n","R: Ampli√° los criterios de b√∫squeda o cambi√° de tema. Es mejor un corpus coherente de 20 textos que uno inconsistente de 30.\n","\n","**P: ¬øPuedo incluir textos de diferentes autores en mi corpus?**  \n","R: S√≠, siempre que tengan coherencia tem√°tica. Por ejemplo: \"Cuentos de terror argentinos contempor√°neos\" de diferentes autores.\n","\n","**P: ¬øC√≥mo manejo textos muy largos (novelas completas)?**  \n","R: Us√° fragmentos representativos (cap√≠tulos) en lugar de novelas completas. Document√° tu criterio de selecci√≥n.\n","\n","### Sobre el An√°lisis T√©cnico\n","\n","**P: ¬øQu√© hago si mi corpus es muy peque√±o y no da resultados interesantes?**  \n","R: Analiz√° las limitaciones en la secci√≥n de conclusiones. Un an√°lisis honesto de un corpus peque√±o es mejor que resultados artificiales.\n","\n","**P: ¬øTengo que usar exactamente las mismas t√©cnicas que vimos en clase?**  \n","R: S√≠, us√° las t√©cnicas vistas. Pod√©s explorar variaciones (diferentes par√°metros, visualizaciones adicionales) pero la base debe ser la misma.\n","\n","**P: ¬øQu√© hago si embeddings no da resultados muy diferentes a BoW?**  \n","R: Document√° esto en tus conclusiones. Es un resultado v√°lido que puede deberse al tipo de corpus o tama√±o. Reflexion√° sobre por qu√© ocurre.\n","\n","**P: ¬øPuedo usar modelos pre-entrenados diferentes al de spaCy?**  \n","R: Preferiblemente us√° spaCy como vimos en clase. Si quer√©s experimentar con otros, hacelo como an√°lisis adicional, no reemplazando spaCy.\n","\n","### Sobre GitHub y la Entrega\n","\n","**P: ¬øQu√© hago si nunca us√© GitHub?**  \n","R: Revis√° los tutoriales recomendados. Tambi√©n pod√©s usar GitHub Desktop o la interfaz web. Empez√° a practicar YA, no esperes al √∫ltimo d√≠a.\n","\n","**P: ¬øPuedo hacer el repositorio privado?**  \n","R: No, debe ser p√∫blico para que puedan evaluarlo. Pod√©s hacerlo privado despu√©s de la evaluaci√≥n si quer√©s.\n","\n","**P: ¬øQu√© pasa si mi notebook es muy pesado para GitHub?**  \n","R: Sub√≠ una versi√≥n \"limpia\" sin outputs muy pesados. Asegurate de que el c√≥digo sea reproducible.\n","\n","**P: ¬øTengo que incluir todos los archivos de texto en el repositorio?**  \n","R: S√≠, inclu√≠ todos los textos que usaste. Si hay problemas de derechos de autor, inclu√≠ solo una muestra y document√° d√≥nde encontrar el resto.\n","\n","### Sobre Evaluaci√≥n y Tiempo\n","\n","**P: ¬øQu√© pasa si no termino todo a tiempo?**  \n","R: Entreg√° lo que tengas completo. Un trabajo parcial bien hecho es mejor que uno completo pero mal ejecutado.\n","\n","**P: ¬øPuedo pedir extensi√≥n del plazo?**  \n","R: Solo en casos excepcionales y justificados. Consult√° con anticipaci√≥n, no el d√≠a de la entrega.\n","\n","**P: ¬øC√≥mo s√© si mi trabajo est√° en el nivel esperado?**  \n","R: Revis√° los criterios de evaluaci√≥n. Si pod√©s responder satisfactoriamente las preguntas de cada secci√≥n, est√°s en buen camino.\n","\n","**P: ¬øPuedo consultar dudas durante el desarrollo?**  \n","R: S√≠, us√° los canales de consulta disponibles. Es mejor consultar dudas espec√≠ficas que estar perdido.\n","\n","---\n","\n","## Mensaje Final\n","\n","Este trabajo integrador es tu oportunidad de demostrar todo lo que aprendiste sobre procesamiento de lenguaje natural. **No es solo un ejercicio acad√©mico**: es una pieza de portafolio que pod√©s mostrar en entrevistas laborales y que refleja tus habilidades reales en NLP.\n","\n","**Consejos para el √©xito**:\n","\n","1. **Empez√° temprano**: No dejes todo para √∫ltimo momento\n","2. **Eleg√≠ un corpus que te interese**: Vas a pasar muchas horas analiz√°ndolo\n","3. **Document√° todo**: Un c√≥digo bien documentado vale m√°s que c√≥digo complejo sin explicaci√≥n\n","4. **S√© honesto**: Si algo no funciona como esperabas, documentalo y reflexion√° sobre por qu√©\n","5. **Ped√≠ ayuda**: No te quedes trabado, consult√° cuando tengas dudas\n","\n","**Record√°**: El objetivo no es hacer el trabajo m√°s complejo, sino demostrar que entend√©s los conceptos y pod√©s aplicarlos apropiadamente. Un an√°lisis simple pero bien ejecutado es mucho mejor que uno complejo pero mal fundamentado.\n","\n","¬°√âxitos con tu trabajo integrador!\n","\n","---\n","\n","*√öltima actualizaci√≥n: 08-09-2025  \n","Curso: Procesamiento de Lenguaje Natural    \n","Profesor: Mat√≠as Barreto  \n","Instituci√≥n: IFTS24*"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}