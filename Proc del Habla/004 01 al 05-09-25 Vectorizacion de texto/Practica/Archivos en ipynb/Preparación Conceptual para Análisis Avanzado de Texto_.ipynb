{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2/AHlwEcQVlzPXHKJ6AR3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"L-3yTjBlHYFD"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"anexo_text_mining.ipynb\n","\n","Automatically generated by Colab.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1L8HtNcjTMdsQ-xWx5VHvIp_f_MfV8kJT\n","\n","# Laboratorio Introductorio: Fundamentos de Text Mining\n","## Preparación Conceptual para Análisis Avanzado de Texto\n","\n","## Mapa Conceptual: Nuestro Recorrido en Procesamiento de Lenguaje Natural\n","\n","### Ubicación Metodológica: ¿Dónde Estamos?\n","\n","En el campo del Procesamiento de Lenguaje Natural existen diferentes enfoques metodológicos que han evolucionado históricamente:\n","\n","**ETAPA 1: MÉTODOS BASADOS EN REGLAS**\n","- Fundamento: \"Le decimos a la máquina exactamente qué hacer\"\n","- Enfoque: Programación explícita con expresiones regulares y diccionarios\n","- Ejemplos: Buscar patrones específicos, validar formatos, extraer información estructurada\n","\n","**ETAPA 2: MÉTODOS ESTADÍSTICOS/FRECUENCIALES** (AQUÍ ESTAMOS HOY)\n","- Fundamento: \"La máquina cuenta y encuentra patrones en los números\"\n","- Enfoque: Análisis de frecuencias y patrones estadísticos\n","- Herramientas: Bag of Words, TF-IDF, análisis de frecuencias\n","- Proyecto: Text Mining con el corpus de Hernán Casciari\n","\n","**ETAPA 3: MACHINE LEARNING TRADICIONAL** (PRÓXIMO DESTINO)\n","- Fundamento: \"La máquina aprende patrones de ejemplos\"\n","- Enfoque: Algoritmos de clasificación y clustering\n","- Ejemplos: Clasificación de sentimientos, detección de spam\n","\n","**ETAPAS FUTURAS**: Redes Neuronales → Modelado de Lenguaje → Transformers → Large Language Models\n","\n","### Criterios de Selección Metodológica\n","\n","**USAR REGLAS cuando:**\n","- El patrón es explícito y conocido\n","- Necesitamos precisión total (ej: validar emails)\n","- El dominio es estrecho y controlado\n","- Ejemplo: Extraer fechas con formato específico\n","\n","**USAR ESTADÍSTICA/FRECUENCIAS cuando:**\n","- Queremos explorar y descubrir patrones\n","- El volumen de datos es grande\n","- Buscamos tendencias y comparaciones\n","- Ejemplo: ¿De qué habla más Casciari cada año?\n","\n","**USAR MACHINE LEARNING cuando:**\n","- Necesitamos generalización a datos nuevos\n","- Los patrones son complejos y no obvios\n","- Tenemos ejemplos etiquetados para entrenar\n","- Ejemplo: Clasificar emails como spam/no-spam\n","\n","### Objetivos de Este Laboratorio\n","\n","Al finalizar esta preparación conceptual podrás:\n","\n","1. **Dominar estructuras de datos Python** esenciales para NLP\n","2. **Aplicar operaciones con Pandas** para análisis textual\n","3. **Interpretar visualizaciones** de text mining\n","4. **Comprender la transición** de Python básico a análisis de texto\n","5. **Conectar conceptos técnicos** con el pipeline de text mining\n","\n","### Metodología de Trabajo\n","\n","1. **Ejecuta las celdas** siguiendo la secuencia propuesta\n","2. **Experimenta modificando** los parámetros de los ejemplos\n","3. **Conecta cada concepto** con el proyecto de análisis de Casciari\n","4. **Resuelve los ejercicios** para consolidar el aprendizaje\n","5. **Reflexiona sobre** las preguntas conceptuales planteadas\n","\n","## De Python a NLP: Conectando Conceptos Fundamentales\n","\n","### El Pipeline de Text Mining: Visión General\n","\n","El procesamiento de textos sigue un pipeline sistemático que transforma texto no estructurado en información cuantificable:\n","\n","1. **EXPLORACIÓN** → ¿Qué datos tenemos?\n","2. **LIMPIEZA** → ¿Qué ruido eliminar?\n","3. **TOKENIZACIÓN** → ¿Cómo dividir el texto?\n","4. **FILTRADO** → ¿Qué palabras importan?\n","5. **VECTORIZACIÓN** → ¿Cómo representar numéricamente?\n","6. **ANÁLISIS** → ¿Qué patrones emergen?\n","7. **VISUALIZACIÓN** → ¿Cómo comunicar hallazgos?\n","\n","### Transformaciones Conceptuales Clave\n","\n","**Listas → Vocabularios**\n","Las listas de Python se convierten en vocabularios de nuestro corpus. Cada palabra única se convierte en una dimensión de análisis.\n","\n","**Diccionarios → Vectores de Frecuencia**\n","Los conteos de palabras se almacenan en diccionarios que posteriormente se transforman en vectores numéricos para análisis matemático.\n","\n","**DataFrames → Matrices Documento-Término**\n","La estructura bidimensional de pandas permite representar corpus completos: cada fila es un documento, cada columna es una palabra.\n","\n","**Lambda + apply() → Transformaciones Masivas**\n","Las funciones lambda con apply() nos permiten procesar miles de documentos aplicando operaciones de limpieza y transformación de manera eficiente.\n","\n","### El Caso Casciari: Hilo Conductor del Análisis\n","\n","Trabajaremos con los cuentos de Hernán Casciari (2004-2015) como corpus de estudio porque:\n","\n","- **Dimensión temporal**: 12 años de evolución lingüística\n","- **Coherencia estilística**: Un único autor, estilo personal reconocible\n","- **Riqueza temática**: Temas familiares, sociales y autobiográficos\n","- **Volumen manejable**: Suficiente para análisis significativo, no abrumador para aprender\n","\n","Este corpus nos permitirá observar cómo las técnicas de text mining revelan patrones que serían imposibles de detectar mediante lectura manual.\n","\n","## Parte 1: Estructuras de Datos Python para Text Mining\n","\n","### Listas: Fundamento de los Vocabularios\n","\n","En text mining, las listas almacenan secuencias ordenadas de elementos textuales: palabras, frases, o documentos completos. Dominar las operaciones básicas con listas es esencial para manipular corpus de texto.\n","\"\"\"\n","\n","# Ejemplo: Construyendo un vocabulario temático de Casciari\n","palabras_casciari = [\"libro\", \"padre\", \"fútbol\", \"escritura\", \"familia\"]\n","print(\"Vocabulario inicial:\", palabras_casciari)\n","\n","# Operaciones esenciales para text mining\n","palabras_casciari.append(\"argentina\")  # Añadir términos nuevos\n","palabras_casciari.extend([\"blog\", \"cuento\"])  # Expandir vocabulario\n","print(\"Vocabulario expandido:\", palabras_casciari)\n","\n","# Acceso y manipulación\n","print(\"Primera palabra temática:\", palabras_casciari[0])\n","print(\"Últimas dos palabras:\", palabras_casciari[-2:])\n","print(\"Total de términos:\", len(palabras_casciari))\n","\n","## **Ejercicio 1: Construcción de Vocabulario**\n","\n","## Instrucciones: Agrega tres palabras más relacionadas con la temática de Casciari (familia, literatura, Argentina) y muestra el vocabulario final con su longitud total.\n","\n","\"\"\"### Diccionarios: Vectores de Frecuencia\n","\n","Los diccionarios representan la estructura fundamental para contar frecuencias de palabras. En text mining, cada diccionario puede representar un documento como vector de frecuencias término-valor.\n","\"\"\"\n","\n","# Ejemplo: Representando un documento como vector de frecuencias\n","documento_casciari = {\n","    \"título\": \"Más respeto, que soy tu madre\",\n","    \"año_publicacion\": 2005,\n","    \"temas_principales\": [\"familia\", \"humor\", \"argentina\"],\n","    \"palabras_frecuentes\": {\n","        \"madre\": 45,\n","        \"hijo\": 32,\n","        \"casa\": 28,\n","        \"familia\": 23,\n","        \"argentina\": 15\n","    }\n","}\n","\n","# Acceso a información estructurada\n","print(\"Análisis del documento:\", documento_casciari[\"título\"])\n","print(\"Año:\", documento_casciari[\"año_publicacion\"])\n","print(\"Palabra más frecuente:\", max(documento_casciari[\"palabras_frecuentes\"],\n","                                   key=documento_casciari[\"palabras_frecuentes\"].get))\n","\n","# Modificación dinámica (simulando actualización de conteos)\n","documento_casciari[\"palabras_frecuentes\"][\"humor\"] = 41\n","print(\"Frecuencia de 'humor':\", documento_casciari[\"palabras_frecuentes\"][\"humor\"])\n","\n","## **Ejercicio 2: Vector de Frecuencias**\n","\n","## Instrucciones: Añade una nueva entrada al diccionario \"palabras_frecuentes\" con la clave \"escritura\" y un valor de frecuencia de tu elección. Luego imprime el diccionario actualizado y identifica las tres palabras más frecuentes.\n","\n","# Simulación de matriz documento-término para corpus de Casciari\n","import pandas as pd\n","\n","# Datos que representan frecuencias de palabras por año\n","corpus_casciari = {\n","    'Año': ['2004', '2005', '2006', '2007'],\n","    'padre': [45, 32, 28, 35],\n","    'madre': [23, 45, 18, 22],\n","    'fútbol': [67, 45, 52, 41],\n","    'escritura': [12, 28, 34, 29],\n","    'argentina': [31, 28, 25, 33]\n","}\n","\n","df_casciari = pd.DataFrame(corpus_casciari)\n","df_casciari = df_casciari.set_index('Año')  # Año como índice para mejor interpretación\n","\n","print(\"Matriz Documento-Término del Corpus de Casciari:\")\n","print(df_casciari)\n","print(\"\\nDimensiones de la matriz:\", df_casciari.shape)\n","print(\"Documentos (filas):\", df_casciari.shape[0])\n","print(\"Vocabulario (columnas):\", df_casciari.shape[1])\n","\n","# Operaciones de análisis en la matriz documento-término\n","\n","# Por columna (análisis de palabras a través del tiempo)\n","print(\"Evolución de la palabra 'padre' por año:\")\n","print(df_casciari['padre'])\n","print()\n","\n","# Por fila (perfil vocabular de un año específico)\n","print(\"Perfil léxico del año 2005:\")\n","print(df_casciari.loc['2005'])\n","print()\n","\n","# Por condición (filtrado analítico)\n","print(\"Años donde 'fútbol' aparece más de 50 veces:\")\n","años_futbol_alto = df_casciari[df_casciari['fútbol'] > 50]\n","print(años_futbol_alto)\n","\n","\"\"\"### Interpretación Conceptual de la Matriz\n","\n","**Analogía fundamental:**\n","Imagina la matriz como una tabla de Excel donde:\n","- **Filas = Documentos** (en nuestro caso, años de escritura de Casciari)\n","- **Columnas = Palabras** del vocabulario total\n","- **Valores = Frecuencias** de aparición de cada palabra en cada documento\n","\n","**Ventajas analíticas:**\n","- **Comparación temporal:** ¿Cómo evoluciona el uso de una palabra?\n","- **Perfil léxico:** ¿Qué caracteriza el vocabulario de un período?\n","- **Análisis cuantitativo:** ¿Qué palabras dominan cada época?\n","\n","**Ejercicio 3: Análisis de Matriz Documento-Término**\n","\n","Instrucciones:\n","1. Añade una nueva columna \"blog\" al DataFrame con valores [15, 22, 18, 25]\n","2. Identifica qué año tuvo la mayor frecuencia total de palabras\n","3. Encuentra qué palabra tiene la mayor variabilidad entre años (diferencia entre máximo y mínimo)\n","\n","## Parte 3: Visualización para Text Mining\n","\n","### Gráficos de Frecuencias: Primera Aproximación Analítica\n","\n","La visualización transforma matrices de frecuencias en insights comprensibles. Los gráficos de barras son fundamentales para comparar frecuencias de términos e identificar patrones dominantes.\n","\"\"\"\n","\n","import matplotlib.pyplot as plt\n","\n","# Análisis de frecuencias para un año específico\n","año_analisis = '2005'\n","frecuencias_2005 = df_casciari.loc[año_analisis]\n","\n","# Visualización de perfil léxico\n","plt.figure(figsize=(10, 6))\n","plt.bar(frecuencias_2005.index, frecuencias_2005.values, color='skyblue', edgecolor='navy')\n","plt.title(f'Perfil de Frecuencias Léxicas - Casciari {año_analisis}', fontsize=14, fontweight='bold')\n","plt.xlabel('Términos del Vocabulario')\n","plt.ylabel('Frecuencia de Aparición')\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', alpha=0.3)\n","\n","# Añadir valores encima de las barras\n","for i, v in enumerate(frecuencias_2005.values):\n","    plt.text(i, v + 1, str(v), ha='center', va='bottom', fontweight='bold')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"Interpretación: En {año_analisis}, '{frecuencias_2005.idxmax()}' fue el término más frecuente con {frecuencias_2005.max()} apariciones.\")\n","\n","# Comparación: Función tradicional vs Lambda\n","\n","# Función tradicional para normalizar frecuencias\n","def normalizar_frecuencia(frecuencia, total):\n","    return frecuencia / total\n","\n","# Equivalente con lambda (más concisa)\n","normalizar_lambda = lambda x, total: x / total\n","\n","# Ejemplo de uso en context de text mining\n","total_palabras_2005 = df_casciari.loc['2005'].sum()\n","print(f\"Total de palabras analizadas en 2005: {total_palabras_2005}\")\n","\n","# Aplicación con función tradicional\n","freq_padre_normalizada = normalizar_frecuencia(df_casciari.loc['2005', 'padre'], total_palabras_2005)\n","print(f\"Frecuencia normalizada de 'padre' (función): {freq_padre_normalizada:.3f}\")\n","\n","# Aplicación con lambda\n","freq_padre_lambda = normalizar_lambda(df_casciari.loc['2005', 'padre'], total_palabras_2005)\n","print(f\"Frecuencia normalizada de 'padre' (lambda): {freq_padre_lambda:.3f}\")\n","\n","\"\"\"### Apply(): Transformación Vectorizada de Corpus\n","\n","Apply() es la herramienta fundamental para procesar corpus completos. Permite aplicar funciones a filas o columnas enteras de manera eficiente.\n","\"\"\"\n","\n","# Ejemplo práctico: Normalización de frecuencias por documento\n","# Crear columnas de frecuencias relativas (porcentajes)\n","\n","# Calcular totales por fila (documento)\n","totales_por_año = df_casciari.sum(axis=1)\n","print(\"Total de palabras por año:\")\n","print(totales_por_año)\n","print()\n","\n","# Aplicar normalización usando lambda y apply\n","# axis=1 significa aplicar función por fila\n","df_normalizado = df_casciari.apply(lambda fila: fila / fila.sum(), axis=1)\n","\n","print(\"Matriz de frecuencias relativas (proporciones):\")\n","print(df_normalizado.round(3))  # Redondear para mejor visualización\n","print()\n","\n","# Verificación: cada fila debe sumar 1.0\n","print(\"Verificación - suma de proporciones por año:\")\n","print(df_normalizado.sum(axis=1))\n","\n","\"\"\"### Apply(): Transformación Vectorizada de Corpus\n","\n","Apply() es la herramienta fundamental para procesar corpus completos. Permite aplicar funciones a filas o columnas enteras de manera eficiente.\n","\"\"\"\n","\n","# Ejemplo práctico: Normalización de frecuencias por documento\n","# Crear columnas de frecuencias relativas (porcentajes)\n","\n","# Calcular totales por fila (documento)\n","totales_por_año = df_casciari.sum(axis=1)\n","print(\"Total de palabras por año:\")\n","print(totales_por_año)\n","print()\n","\n","# Aplicar normalización usando lambda y apply\n","# axis=1 significa aplicar función por fila\n","df_normalizado = df_casciari.apply(lambda fila: fila / fila.sum(), axis=1)\n","\n","print(\"Matriz de frecuencias relativas (proporciones):\")\n","print(df_normalizado.round(3))  # Redondear para mejor visualización\n","print()\n","\n","# Verificación: cada fila debe sumar 1.0\n","print(\"Verificación - suma de proporciones por año:\")\n","print(df_normalizado.sum(axis=1))\n","\n","\"\"\"**Ejercicio 5: Transformación de Corpus**\n","\n","Instrucciones: Crea una nueva columna \"longitud_texto\" que contenga el número de caracteres de cada texto procesado usando lambda y apply().\n","\"\"\"\n","\n","# Simulación del patrón típico en text mining\n","# (Similar a lo que veremos en el laboratorio principal)\n","\n","def procesar_documento_casciari(texto_simulado):\n","    \"\"\"Simula función de limpieza de texto\"\"\"\n","    # En el laboratorio real, esto sería clean_text_round1(texto)\n","    return texto_simulado.lower().replace(\".\", \"\").replace(\",\", \"\")\n","\n","# Datos simulados de documentos\n","documentos_ejemplo = pd.DataFrame({\n","    'año': ['2004', '2005', '2006'],\n","    'texto_original': [\n","        \"El padre jugaba fútbol en Argentina.\",\n","        \"La madre escribía sobre la familia.\",\n","        \"Los libros hablaban de fútbol argentino.\"\n","    ]\n","})\n","\n","# Aplicar transformación usando lambda + apply\n","documentos_ejemplo['texto_procesado'] = documentos_ejemplo['texto_original'].apply(\n","    lambda texto: procesar_documento_casciari(texto)\n",")\n","\n","print(\"Comparación: Texto Original vs Procesado\")\n","print(\"=\" * 50)\n","for i, fila in documentos_ejemplo.iterrows():\n","    print(f\"Año {fila['año']}:\")\n","    print(f\"  Original:   {fila['texto_original']}\")\n","    print(f\"  Procesado:  {fila['texto_procesado']}\")\n","    print()\n","\n","\"\"\"### Conceptualización de la Serialización\n","\n","Pickle convierte objetos Python complejos en flujos de bytes que pueden guardarse en disco y recuperarse posteriormente sin pérdida de información. Es fundamental para proyectos de text mining donde:\n","\n","- El procesamiento es computacionalmente costoso\n","- Los resultados intermedios necesitan preservarse\n","- Se requiere compartir análisis entre sesiones o colaboradores\n","\n","## Parte 5: Persistencia de Datos con Pickle\n","\n","### Serialización en Text Mining\n","\n","En proyectos de text mining, los corpus procesados y las matrices documento-término representan horas de computación. Pickle permite guardar estos objetos complejos para reutilización posterior.\n","\"\"\"\n","\n","import pickle\n","\n","# 1. Serialización: Guardar matrices y análisis procesados\n","corpus_analizado = {\n","    \"matriz_frecuencias\": df_casciari,\n","    \"matriz_normalizada\": df_normalizado,\n","    \"metadatos\": {\n","        \"autor\": \"Hernán Casciari\",\n","        \"período\": \"2004-2007\",\n","        \"total_documentos\": len(df_casciari),\n","        \"vocabulario_size\": len(df_casciari.columns)\n","    }\n","}\n","\n","# Guardar el análisis completo\n","with open(\"analisis_casciari.pkl\", \"wb\") as archivo:\n","    pickle.dump(corpus_analizado, archivo)\n","    print(\"Análisis de corpus serializado y guardado exitosamente\")\n","\n","# Ventajas en text mining:\n","# - Evita recalcular vectorizaciones costosas\n","# - Preserva estructuras de datos complejas\n","# - Permite compartir análisis entre sesiones\n","\n","# 2. Deserialización: Recuperar análisis previos\n","with open(\"analisis_casciari.pkl\", \"rb\") as archivo:\n","    datos_recuperados = pickle.load(archivo)\n","    print(\"Análisis recuperado exitosamente\")\n","\n","# Verificar que los datos se restauraron correctamente\n","print(\"\\nMetadatos del análisis:\")\n","for clave, valor in datos_recuperados[\"metadatos\"].items():\n","    print(f\"  {clave}: {valor}\")\n","\n","print(\"\\nPrimeras filas de la matriz recuperada:\")\n","print(datos_recuperados[\"matriz_frecuencias\"].head())\n","\n","\"\"\"**Ejercicio 6: Persistencia de Análisis**\n","\n","Instrucciones: Crea un diccionario que contenga tanto el DataFrame original como el normalizado, añade metadatos sobre el vocabulario total, y guárdalo usando pickle con el nombre \"mi_analisis_textual.pkl\".\n","\n","## Parte 6: Interpretación de Visualizaciones en Text Mining\n","\n","### Preparación para el Análisis de Word Clouds\n","\n","En el laboratorio principal trabajaremos con nubes de palabras (word clouds) como herramienta de visualización. Estas representaciones gráficas requieren habilidades interpretativas específicas.\n","\n","### Metodología de Interpretación de Word Clouds\n","\n","**Elementos visuales clave:**\n","- **Tamaño de palabra** = Frecuencia relativa en el corpus\n","- **Posición** = Principalmente estética (sin significado analítico)\n","- **Color** = Estético o categórico según configuración\n","\n","**Preguntas analíticas fundamentales:**\n","\n","1. **Identificación de dominancias temáticas:**\n","   - ¿Qué palabras aparecen más prominentes?\n","   - ¿Qué temas se pueden inferir de las palabras grandes?\n","\n","2. **Análisis temporal comparativo:**\n","   - Al comparar word clouds de diferentes períodos: ¿Qué temas emergen o desaparecen?\n","   - ¿Qué palabras cambian de tamaño significativamente?\n","\n","3. **Contextualización biográfica:**\n","   - ¿Cómo se relacionan las palabras prominentes con eventos conocidos del autor?\n","   - ¿Qué patrones reflejan cambios en la vida personal o profesional?\n","\n","### Aplicación al Caso Casciari\n","\n","**Contexto biográfico relevante:**\n","- **2004**: Nacimiento de su hija → Expectativa de vocabulario familiar\n","- **2005**: Publicación de \"Más respeto, que soy tu madre\" → Posible énfasis en temas maternales\n","- **Evolución temporal**: De temas familiares a temas profesionales y literarios\n","\n","**Hipótesis interpretativas a contrastar:**\n","- Incremento gradual de vocabulario relacionado con paternidad post-2004\n","- Variación en la prominencia de términos futbolísticos según contextos deportivos\n","- Evolución del vocabulario literario paralela al crecimiento de su carrera como escritor\n","\n","## Síntesis y Preparación para el Laboratorio Principal\n","\n","### Conceptos Integrados\n","\n","Has trabajado con las herramientas fundamentales del text mining:\n","\n","**Estructuras de datos:**\n","- Listas → Vocabularios y secuencias textuales\n","- Diccionarios → Vectores de frecuencias término-valor\n","- DataFrames → Matrices documento-término\n","\n","**Transformaciones:**\n","- Lambda + apply() → Procesamiento vectorizado de corpus\n","- Normalización → Frecuencias relativas y comparaciones válidas\n","- Serialización → Persistencia de análisis complejos\n","\n","**Análisis:**\n","- Identificación de patrones frecuenciales\n","- Comparaciones temporales y temáticas\n","- Interpretación de visualizaciones especializadas\n","\n","### Transición al Text Mining Avanzado\n","\n","El laboratorio principal aplicará estos conceptos a escala real:\n","- Corpus de 386 documentos (vs 4 simulados aquí)\n","- Vocabulario de miles de términos (vs 5 palabras ejemplo)\n","- Pipeline completo de limpieza y procesamiento\n","- Análisis estadístico comprehensivo\n","- Visualizaciones profesionales con interpretación contextual\n","\n","### Preguntas de Reflexión Final\n","\n","1. **Metodológica**: ¿Qué ventajas ofrece el enfoque estadístico/frecuencial comparado con métodos basados en reglas?\n","\n","2. **Técnica**: ¿Cómo se relaciona cada estructura de datos Python con los componentes del pipeline de text mining?\n","\n","3. **Analítica**: ¿Qué tipos de insights esperarías obtener del análisis completo del corpus de Casciari?\n","\n","4. **Conceptual**: ¿En qué punto crees que sería necesario pasar de métodos frecuenciales a machine learning?\n","\n","Estas bases conceptuales y técnicas te permitirán abordar el análisis completo con comprensión profunda de cada etapa del proceso.\n","\"\"\""]}]}