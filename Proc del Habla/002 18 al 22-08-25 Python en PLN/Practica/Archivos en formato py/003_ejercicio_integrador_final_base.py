# -*- coding: utf-8 -*-
"""003_Ejercicio Integrador Final-Base.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U05MJfWJ1zLL5BMqo6poyxaUXwptBQZI

# Clase 2: Estructuras Avanzadas y Aplicaciones en PLN üõ†Ô∏è

Ya vimos los elementos minimos fudamentales de Python (variables, condicionales). Hoy, vamos a construir con ellos: crearemos herramientas reutilizables, organizaremos nuestro c√≥digo de manera profesional y, al final, ¬°construiremos una aplicaci√≥n web interactiva para analizar texto!

## Hoja de Ruta (2 horas)
1.  **Calentamiento: Manipulaci√≥n Avanzada de Texto** (20 min)
2.  **Funciones: Creando Herramientas a Medida** (25 min)
3.  **Programaci√≥n Orientada a Objetos (POO): El Salto a un C√≥digo Profesional** (30 min)
4.  **Ejercicio Pr√°ctico 1: Expandiendo Nuestras Clases** (15 min)
5.  **Ejercicio Integrador Final: De Python a Aplicaci√≥n Web con Gradio** (30 min)

## 1. Calentamiento: Manipulaci√≥n Avanzada de Texto

En PLN, el 90% del trabajo es "limpiar" y "preparar" el texto. Por suerte, los strings en Python vienen con "superpoderes" incorporados llamados **m√©todos**, que nos facilitan enormemente esta tarea.
"""

# üßπ .strip() elimina espacios en blanco al principio y final del texto.
# Es importante para evitar errores en comparaci√≥n de strings o tokens.
# En PLN, se usa justo despu√©s de extraer texto de documentos o web scraping.

# üî† .lower() convierte todo el texto a min√∫sculas.
# Esto permite comparar palabras sin importar las may√∫sculas (ej: "Hola" = "hola").

# üî° .upper() hace lo opuesto: convierte a may√∫sculas.
# Puede servir en an√°lisis visuales o normalizaci√≥n para sistemas legados.

# üîÑ .replace('A', 'B') reemplaza una palabra o s√≠mbolo por otro.
# En PLN se usa para eliminar o transformar caracteres no deseados (como signos de puntuaci√≥n, hashtags, etc).

# ‚úÇÔ∏è .split() separa el texto en una lista de palabras.
# Es un primer paso para tokenizar, aunque no es la tokenizaci√≥n profesional (como la de spaCy o nltk).

# üßµ ' '.join(lista) toma una lista de palabras y las une con espacios (o cualquier otro separador).
# Es √∫til para volver a construir oraciones o generar strings de salida.

# M√©todos √∫tiles de strings que usaremos constantemente
texto = "  Procesamiento del Lenguaje Natural en el Rio de la Plata "

# .strip() -> Elimina espacios en blanco al inicio y al final
print(f"Original: '{texto}'")
print(f"Con .strip(): '{texto.strip()}'")

# .lower() y .upper() -> Convierten a min√∫sculas y may√∫sculas
print(f"Con .lower(): '{texto.lower()}'")
print(f"Con .upper(): '{texto.upper()}'")

# .replace('viejo', 'nuevo') -> Reemplaza una parte del texto por otra
print(f"Con .replace(): '{texto.replace('Lenguaje', 'Idioma')}'")

# .split() -> Divide un string en una lista de palabras (¬°lo vimos en la Clase 1!)
print(f"Con .split(): {texto.split()}")

# 'separador'.join(lista) -> Une los elementos de una lista en un solo string
palabras_a_unir = ["El", "NLP", "es", "genial"]
print(f"Con .join(): '{' '.join(palabras_a_unir)}'")

"""## 2. Funciones: Creacion de Herramientas a Medida

Ya sabemos crear funciones, pero ahora vamos a usarlas como lo hacen los profesionales: para encapsular una l√≥gica espec√≠fica y hacer nuestro c√≥digo m√°s limpio y reutilizable. Una buena funci√≥n hace **una sola cosa y la hace bien**.

Vamos a crear una funci√≥n que limpie un texto y otra que, usando la primera, cuente las palabras.
"""

# Funci√≥n 1: Especializada en limpiar texto
def limpiar_texto(texto):
    """Limpia un texto removiendo caracteres de puntuaci√≥n comunes."""
    caracteres_especiales = ['.', ',', '!', '?', ';', ':']
    texto_limpio = texto
    for char in caracteres_especiales:
        texto_limpio = texto_limpio.replace(char, '')
    return texto_limpio.lower() # Devuelve el texto limpio y en min√∫sculas

# Funci√≥n 2: Especializada en contar palabras

def contar_palabras(texto):
    """Usa limpiar_texto() para procesar el texto y luego cuenta las palabras."""
    texto_procesado = limpiar_texto(texto) # ¬°Reutilizamos nuestra primera funci√≥n!
    palabras = texto_procesado.split()
    return len(palabras)

# Definimos una funci√≥n llamada contar_palabras que recibe un texto como argumento.
# Usamos .lower() para convertir todo a min√∫sculas (opcional en este caso).
# Luego usamos .split() para dividir el texto en palabras.
# Finalmente, usamos len() para contar cu√°ntas palabras hay.

# --- Uso de las funciones ---
mi_texto = "¬°Hola, mundo! ¬øListo/a para aprender sobre Procesamiento del Lenguaje Natural?"
cantidad = contar_palabras(mi_texto)

print(f"El texto original era: '{mi_texto}'")
print(f"Despu√©s de limpiarlo y contarlo, tiene {cantidad} palabras.")

# Probamos la funci√≥n con una frase.
# 'cantidad' almacena el n√∫mero total de palabras encontradas.
# Imprimimos el resultado.

texto = "El procesamiento del lenguaje natural es una rama de la inteligencia artificial"
cantidad = contar_palabras(texto)
print(f"El texto original era: '{texto.upper()}'")
print(f"El texto original era: '{texto.lower()}'")
print(f"Despu√©s de limpiarlo y contarlo, tiene {cantidad} palabras.")

"""## 3. Programaci√≥n Orientada a Objetos (POO): Un C√≥digo m√°s Inteligente

La POO es un paradigma para organizar el c√≥digo. La idea es simple: en lugar de tener datos y funciones por separado, los agrupamos en "objetos" que tienen tanto los datos (atributos) como las funciones que operan sobre esos datos (m√©todos).

* **Clase**: Es el "plano" o la "receta". Define c√≥mo ser√°n los objetos.
* **Objeto (o instancia)**: Es la "casa" construida a partir del plano. Es una entidad real con la que interactuamos.
* **`__init__(self, ...)`**: El "constructor". Es un m√©todo especial que se ejecuta al crear un nuevo objeto para inicializar sus atributos.
* **`self`**: Se refiere al objeto mismo. As√≠ es como el objeto accede a sus propios datos y m√©todos.

Vamos a crear una clase `ProcesadorTexto` que encapsule un texto y todas las operaciones que queremos hacer con √©l.
"""

# Definiendo el "plano" para nuestros procesadores de texto
class ProcesadorTexto:
    # El constructor: se ejecuta cuando creamos un objeto con ProcesadorTexto("...")
    def __init__(self, texto):
        print(f"‚ú® Creando un nuevo procesador para el texto: '{texto[:30]}...'")
        self.texto_original = texto
        self.texto_limpio = self.texto_original.lower().strip('.,!?')
        self.palabras = self.texto_limpio.split()

    # Un m√©todo para contar palabras
    def contar_palabras(self):# M√©todo que cuenta cu√°ntas palabras hay en el documento, usando la lista ya procesada.
        return len(self.palabras)

    # Un m√©todo para contar palabras √∫nicas (sin repeticiones)
    def contar_palabras_unicas(self):
        return len(set(self.palabras)) # 'set' elimina duplicados autom√°ticamente

    # Un m√©todo para calcular la frecuencia de cada palabra
    def calcular_frecuencia(self):
        frecuencia = {}
        for palabra in self.palabras:
            frecuencia[palabra] = frecuencia.get(palabra, 0) + 1
        return frecuencia

# El m√©todo __init__ se ejecuta autom√°ticamente cuando creamos un nuevo Documento.
# Guarda el texto original en self.texto.
# Tambi√©n prepara una lista de palabras en min√∫scula (tokenizaci√≥n b√°sica) y la guarda en self.palabras.
# La variable self hace referencia al propio objeto que estamos creando.

# --- Uso de la clase ---
# Creamos un objeto (una instancia) de nuestra clase
procesador = ProcesadorTexto("Python para NLP es genial porque Python es vers√°til.")

# Ahora podemos usar sus m√©todos
print(f"Total de palabras: {procesador.contar_palabras()}")
print(f"Palabras √∫nicas: {procesador.contar_palabras_unicas()}")
print(f"Frecuencia de palabras: {procesador.calcular_frecuencia()}")

procesador = ProcesadorTexto("""Pr√°cticamente, no existe hoy en d√≠a una faceta de la realidad de la cual no se disponga
informaci√≥n de manera electr√≥nica, ya sea estructurada, en forma de bases de datos, o no
estructurada, en forma textual o hipertextual. Desgraciadamente, gran parte de esta
informaci√≥n se genera con un fin concreto y posteriormente no se analiza ni integra con el
resto de informaci√≥n o conocimiento del dominio de actuaci√≥n. Un ejemplo claro podemos
encontrarlo en muchas empresas y organizaciones, donde existe una base de datos
transaccional (el sistema de informaci√≥n de la organizaci√≥n) que sirve para el funcionamiento
de las aplicaciones del d√≠a a d√≠a, pero que raramente se utiliza con fines anal√≠ticos. Esto
se debe, fundamentalmente, a que no se sabe c√≥mo hacerlo, es decir, no se dispone de las
personas y de las herramientas indicadas para ello.
Afortunadamente, la situaci√≥n ha cambiado de manera significativa respecto a unos
a√±os atr√°s, donde el an√°lisis de datos se realizaba exclusivamente en las grandes
corporaciones, gobiernos y entidades bancarias, por departamentos especializados con
nombres diversos: planificaci√≥n y prospectiva, estad√≠stica, log√≠stica, investigaci√≥n operativa,
etc. Tanto la tecnolog√≠a inform√°tica actual, la madurez de las t√©cnicas de aprendizaje
autom√°tico y las nuevas herramientas de miner√≠a de datos de sencillo manejo, permiten a
una peque√±a o mediana organizaci√≥n (o incluso un particular) tratar los grandes
vol√∫menes de datos almacenados en las bases de datos (propias de la organizaci√≥n,
externas o en la web).""")

# Ahora podemos usar sus m√©todos
print(f"Total de palabras: {procesador.contar_palabras()}")
print(f"Palabras √∫nicas: {procesador.contar_palabras_unicas()}")
print(f"Frecuencia de palabras: {procesador.calcular_frecuencia()}")

#üîç ¬øPor qu√© usar clases en PLN?
#üì¶ Permiten empaquetar texto + funciones en un solo lugar
#‚úÖ Hacen que el c√≥digo sea m√°s reutilizable y legible
#üß© Se pueden extender f√°cilmente (por ejemplo, agregar normalizaci√≥n, conteo de frecuencias, limpieza, etc.)
#üß† Se asemejan a c√≥mo modelamos el mundo real: un documento tiene texto, palabras, metadatos...

"""## 4. Ejercicio Pr√°ctico 1: Expandiendo Nuestra Clase

¬°Tu turno! Vamos a agregarle m√°s "poder" a nuestra clase `ProcesadorTexto`.

**Tu objetivo:** A√±ad√≠ un nuevo m√©todo a la clase llamado `calcular_longitud_media()`. Este m√©todo debe calcular y devolver la longitud promedio de las palabras en el texto.

**Pista:** Deber√°s sumar la longitud de todas las palabras y dividirla por el n√∫mero total de palabras.
"""

# Pega la clase ProcesadorTexto ac√° y a√±√°dile tu nuevo m√©todo.

class ProcesadorTexto:
    def __init__(self, texto):
        self.texto_original = texto
        self.texto_limpio = self.texto_original.lower().strip('.,!?')
        self.palabras = self.texto_limpio.split()
# El constructor recibe un texto, lo guarda como original y tambi√©n lo limpia:
# - Convierte a min√∫sculas para normalizar
# - Elimina signos de puntuaci√≥n b√°sicos con .strip()
# - Divide el texto en palabras con .split() para obtener una lista de tokens


    def contar_palabras(self):
        return len(self.palabras)
# Devuelve el total de palabras del texto ya procesado.
#üìå PLN: Longitud del documento ‚Üí √∫til para calcular m√©tricas como longitud promedio, densidad l√©xica, etc.

    def contar_palabras_unicas(self):
        return len(set(self.palabras))
# Devuelve la cantidad de palabras √∫nicas (sin repetir) en el texto.
#üìå PLN: Muy √∫til para calcular diversidad l√©xica, o para entrenar vocabularios.


    def contiene(self, palabra):
        return palabra.lower() in self.palabras
# Verifica si la palabra indicada est√° presente en el documento, ignorando may√∫sculas.
#üìå PLN: Sirve para detecci√≥n de keywords (palabras ofensivas, etiquetas, temas).

    def calcular_frecuencia(self):
        frecuencia = {}
        for palabra in self.palabras:
            frecuencia[palabra] = frecuencia.get(palabra, 0) + 1
        return frecuencia
# Recorre las palabras del texto y calcula cu√°ntas veces aparece cada una.
# Devuelve un diccionario {palabra: frecuencia}
#üìå PLN: Esta t√©cnica es base para: nubes de palabras / TF-IDF / clasificaci√≥n basada en bolsa de palabras

    def calcular_longitud_media(self):
        if not self.palabras: # Evitar divisi√≥n por cero si el texto est√° vac√≠o
            return 0
        total_letras = sum(len(palabra) for palabra in self.palabras)
        return total_letras / len(self.palabras)
# Calcula la longitud promedio de las palabras en el documento.
# Si no hay palabras, devuelve 0 para evitar divisi√≥n por cero.
#üìå PLN: Puede usarse como indicador de complejidad o estilo de escritura.

#Aqu√≠ estoy probando lo anterior
procesador_prueba = ProcesadorTexto("""Cualquier profesional o particular puede tener inter√©s o necesidad de analizar sus datos,
desde un comercial que desea realizar un agrupamiento de sus clientes, hasta un broker que
pretende utilizar la miner√≠a de datos para analizar el mercado de valores, pasando por un
psiquiatra que intenta clasificar sus pacientes en violentos o no violentos a partir de sus
comportamientos anteriores. Los problemas y las dudas a la hora de cubrir estas
necesidades aparecen si se desconoce por d√≥nde empezar, qu√© herramientas utilizar, qu√©
t√©cnicas estad√≠sticas o de aprendizaje autom√°tico son m√°s apropiadas y qu√© tipo de
conocimiento puedo llegar a obtener y con qu√© fiabilidad. Este libro intenta resolver estas
dudas pero, adem√°s, presenta una serie de posibilidades y, por supuesto, de limitaciones,
que ni el comercial, el broker o el psiquiatra podr√≠an haberse planteado sin conocer las bases
de la tecnolog√≠a de la extracci√≥n de conocimiento a partir de datos.
La necesidad o el inter√©s, ante un problema concreto, es una manera habitual de
reciclarse y de aprender una nueva tecnolog√≠a. No obstante, la anticipaci√≥n o la
preparaci√≥n es otra raz√≥n muy importante para adquirir un determinado conocimiento. No
es de extra√±ar, por ello, que cada d√≠a existan m√°s materias y contenidos sobre ‚Äúminer√≠a de
datos‚Äù en estudios de nivel superior, sean grados universitarios o m√°steres, as√≠ como en
cursos organizados por empresas acerca de esta tecnolog√≠a (generalmente centrada en sus
propias herramientas). Aparecen por tanto un sinf√≠n de asignaturas obligatorias u optativas
en estudios inform√°ticos, ingenieriles, empresariales, de ciencias de la salud y ciencias
sociales, y muchos otros, como complemento o como alternativa a las materias m√°s cl√°sicas
de estad√≠stica que, hasta ahora, estaban m√°s bien centradas en la validaci√≥n de hip√≥tesis
bajo diferentes distribuciones, la teor√≠a de la probabilidad, el an√°lisis multivariante, los
estudios correlacionales o el an√°lisis de la varianza.""")
long_media = procesador_prueba.calcular_longitud_media()
print(f"La longitud media de las palabras es: {long_media:.2f}") # :.2f formatea a 2 decimales

"""‚úÖ En resumen

M√©todo---------------------------¬øPara qu√© sirve?------------------------Concepto PLN

__init__-------------------------------Preprocesar y tokenizar texto-----------Normalizaci√≥n

contar_palabras	------------------Total de palabras	-----------------------Longitud de documento

contar_palabras_unicas-----------Diversidad l√©xica------------------------Vocabulario

contiene--------------------------Buscar t√©rminos------------------------B√∫squeda sem√°ntica

calcular_frecuencia---------------Frecuencia l√©xica-----------------------Bolsa de palabras

calcular_longitud_media----------Complejidad l√©xica----------------------M√©trica de estilo

## 5. Ejercicio Integrador Final: Tu Propia App de An√°lisis de Texto

Lleg√≥ el momento de combinar todo lo que aprendimos. En este desaf√≠o final, no solo usar√°s Python para analizar texto, sino que tambi√©n construir√°s una **aplicaci√≥n web interactiva** con Gradio para mostrar tus resultados al mundo.

**El Objetivo:** Crear una herramienta simple donde un usuario pueda pegar un texto y obtener un an√°lisis b√°sico de PLN al instante.

No te daremos la soluci√≥n completa. En su lugar, te daremos un mapa, las piezas clave y muchas pistas. Este es tu proyecto

---

### üß† Paso 1: El "Cerebro" de la Aplicaci√≥n (La Funci√≥n de An√°lisis)

Primero, necesitamos una funci√≥n principal que orqueste todo el trabajo. Esta funci√≥n recibir√° el texto del usuario, usar√° nuestra clase `ProcesadorTexto` para hacer los c√°lculos y preparar√° los resultados para ser mostrados.

**Instrucciones:**
1.  Completa el c√≥digo de la funci√≥n `analizar_texto(texto)` que te proporcionamos abajo.
2.  Dentro de la funci√≥n, debes **crear un objeto** de la clase `ProcesadorTexto`.
3.  Usa los **m√©todos** de ese objeto (`.contar_palabras()`, `.contar_palabras_unicas()`, etc.) para obtener las m√©tricas.
4.  Formatea un `resumen` en un string amigable para el usuario.
5.  La funci√≥n debe **devolver dos cosas**: el string del resumen y el diccionario de frecuencias.

### ü§ñ Tu Compa√±ero de Programaci√≥n: Usa la IA para Aprender

Como desarrollador/a del presente, tenes acceso a herramientas incre√≠bles. **Te animamos a que uses asistentes de IA como ChatGPT, Gemini, Copilot, etc., como si fueran tu tutor personal.**

No se trata de pedirle la soluci√≥n completa, sino de hacerle preguntas inteligentes para resolver los "TODO" del c√≥digo. Algunos ejemplos de prompts que podr√≠as usar:

* *"Tengo una clase en Python llamada `ProcesadorTexto` que se inicializa con un texto ¬øC√≥mo creo un objeto o instancia de esa clase?"*
* *"En Python ¬øc√≥mo puedo devolver dos variables (un string y un diccionario) desde una funci√≥n?"*
* *"Tengo un diccionario de frecuencias de palabras en Python ¬øC√≥mo encuentro la clave (la palabra) que tiene el valor m√°s alto (la mayor frecuencia)?"*
* *"Expl√≠came qu√© hace el componente `gr.JSON` en la librer√≠a Gradio."*
* *"Mi c√≥digo de Gradio no funciona. ¬øPodes ayudarme a depurarlo? Ac√° est√° mi funci√≥n y mi `gr.Interface`..."*

¬°Experimenta! Preguntar es la mejor forma de aprender.

---
"""

# Aseg√∫rate de que Gradio est√© instalado
!pip install gradio -q
import gradio as gr

# --- Pieza Clave: La Clase que ya construimos ---
# La necesitas para que tu funci√≥n de an√°lisis pueda usarla.
class ProcesadorTexto:
    def __init__(self, texto):
        self.texto_original = texto
        self.texto_limpio = self.texto_original.lower().strip('.,!?')
        self.palabras = self.texto_limpio.split()
    def contar_palabras(self):
        return len(self.palabras)
    def contar_palabras_unicas(self):
        return len(set(self.palabras))
    def calcular_frecuencia(self):
        frecuencia = {}
        for palabra in self.palabras:
            frecuencia[palabra] = frecuencia.get(palabra, 0) + 1
        return frecuencia

# --- PASO 1: Completa la funci√≥n "Cerebro" ---
def analizar_texto(texto):
    """
    Esta funci√≥n es el n√∫cleo de nuestra app.
    Recibe un texto, lo procesa con nuestra clase y devuelve los resultados.
    """
    # Condici√≥n de seguridad por si el usuario no escribe nada.
    if not texto.strip():
        return "Por favor, ingresa algo de texto para analizar.", {}

    # TODO 1: Crea una instancia de la clase ProcesadorTexto
    # Pista: procesador = ProcesadorTexto(texto_ingresado)

    # TODO 2: Usa los m√©todos del objeto para obtener:
    # - Total de palabras
    # - Palabras √∫nicas
    # - Diccionario de frecuencias

    # TODO 3: (Opcional) Encuentra la palabra m√°s frecuente
    # Pista: puedes usar max(diccionario, key=diccionario.get)

    # TODO 4: Crea un string de resumen con formato
    # Ejemplo de formato esperado:
    """
    --- Resumen del An√°lisis ---
    Total de Palabras: 25
    Palabras √önicas: 20
    Palabra M√°s Frecuente: 'python' (3 repeticiones)
    """

    # TODO 5: Devuelve el resumen y el diccionario de frecuencias
    # Pista: return resumen, frecuencia_diccionario

"""### üé® Paso 2: La "Cara" de la Aplicaci√≥n (La Interfaz de Gradio)

Ahora que tenemos el "cerebro", vamos a conectarlo a una interfaz gr√°fica. Ya vimos Gradio, as√≠ que esta parte te resultar√° familiar.

**Instrucciones:**
1.  Observa el esqueleto de `gr.Interface` que te damos.
2.  Asegurate de que el par√°metro `fn` apunte a tu funci√≥n `analizar_texto`.
3.  Defin√≠ los `inputs` y `outputs` correctamente. Queremos una caja de texto grande para la entrada y dos componentes de salida: uno para el resumen y otro para el diccionario de frecuencias.

---
"""

# --- PASO 2: Configura la Interfaz de Gradio ---
demo = gr.Interface(
    # TODO 6: Apunta 'fn' a tu funci√≥n de an√°lisis
    fn=analizar_texto,  # Reemplaza con el nombre de tu funci√≥n

    # Configuraci√≥n de la entrada
    inputs=gr.Textbox(lines=10, placeholder="Escrib√≠ o pega un texto ac√° para analizarlo..."),

    # TODO 7: Configura las salidas
    # Necesitas dos componentes:
    # 1. Un Textbox para el resumen (gr.Textbox())
    # 2. Un JSON para el diccionario (gr.JSON())
    outputs=[
        gr.Textbox(label="Resumen del An√°lisis"),
        gr.JSON(label="Frecuencia de Palabras")
    ],

    # Detalles de la interfaz
    title="üìä Analizador de Texto Interactivo",
    description="Creado por VOS con Python y Gradio. Introduc√≠ texto y descubr√≠ sus secretos.",
    allow_flagging="never"
)

# TODO 8: Descomenta esta l√≠nea cuando tu c√≥digo est√© listo
# demo.launch(share=True)  # share=True crea un enlace p√∫blico temporal

"""---
## Glosario R√°pido de la Clase 2

* **M√©todo**: Una funci√≥n que "pertenece" a un objeto (ej: `mi_texto.strip()`).
* **Clase**: El "plano" o plantilla para crear objetos. Define sus atributos y m√©todos.
* **Objeto/Instancia**: Una entidad concreta creada a partir de una clase.
* **Atributo**: Una variable que "pertenece" a un objeto (ej: `procesador.palabras`).
* **`self`**: Palabra clave dentro de una clase que se refiere a la instancia actual del objeto.
* **POO (Programaci√≥n Orientada a Objetos)**: Un estilo de programaci√≥n basado en la idea de agrupar datos y funciones en objetos.
---
"""